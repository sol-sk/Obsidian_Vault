[[PSYC 217]]

11-24-23 (slides from 11-22-23): from here forward slides will be one class behind BUT DON'T WORRY
#### Type 1 and Type 2 error
![[Screen Shot 2023-12-03 at 1.55.44 PM.png]]
**Power:** 
- Probability of correctly rejecting a false null hypothesis
- The ability to detect an effect *if one truly exists*

Power and type 2 error rate (different sides of same coin) depend on 3 factors: 
- Sample size: bigger sample = greater power
- Magnitude of effect (effect size): Larger difference = greater power
- Alpha level: Larger alpha level = easier to find data consistent with research hypothesis = greater power
	- Lower alpha level = smaller zones of rejection

Larger effect size = lower chance of type 2 error, no effect on type 2 error rate

#### p hacking
- Data peeking: running small sample sizes and checking significance level until it reaches significance
- Creative data trimming: liberally applying the term "outlier".. trimming data until it makes the distribution look better
- Outcome-reporting bias: running a million studies until you hit relevance
- Adding covariates: does predictor improve as you add more covariates (with no prior expectations)
- HARKing 

##### Inferential statistics Learning objectives
- Explain the relationsihp between a sample and a population
- Describe at least 3 errors in judgement that people commonly make
- Discuss the importance of relying on base rate data from large samples
- Define gambler's fallacy
- Generate null and research hypothesis
- List 3 steps in hypothesis testing
- Explain how a sampling distribution is made
- Explain the logic of the numerator and denominator in the t-ratio
- Explain the meaning of statistically significant 
- Compare an obtained statistic to a critical value and decide what to do with the null hypothesis
- Explain when a researcher would use an F test rather than a t test
- Distinguish between Type I and II errors
- Define alpha and power in hypothesis testing
- Describe relationship between effect size, power, and Type I and II errors
- Define and describe p hacking

### Qualitative designs
##### Learning objectives
- Describe pros and cons of quantitative vs qualitative 
- Compare and contrast quantitative and qualitative methods
- Define naturalistic and systemic observation, case studies, and archival research
- Recognize examples of each of the above examples

##### Quantitative methods
- Numerical data
- Statistical analysis
Pros: 
- Excellent for testing hypotheses
- Allow for effects and differences to be measurable and tangible
- Allow us to determine if differences are likely to be due to chance
Cons: 
- Limits understanding of behaviors and thoughts to numerical representations 
- Validity of turning thoughts and behaviors into numbers?
##### Qualitative methods
- Unit of analysis: personal experience and open-ended responses
- Method of analysis: interpretation of response
Pros: 
- Excellent for testing hypotheses
- Allow for in-depth verbal understanding of human behavior
- Escapes issues related to distilling thoughts and behaviors into numbers
Cons: 
- Conclusions may be drawn due to random chance or personal biases
- Can be extremely time-consuming and difficult to interpret

##### Naturalistic observation
- Obtain gather record info from people in the "field"
- Can sidestep ethically problematic experimental manipulations 
**Participant observation**
- Observer is participating along with people being observed
- Purpose is made known to people in the group
	â†’ Participant reactivity can be confound
**Concealed observation**
- Eitehr the observation is concealed or the purpose of the observation is concealed
- Ethical considerations: may be problematic