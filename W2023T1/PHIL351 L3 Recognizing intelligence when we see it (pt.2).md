#philosophy 
#cogs 

[[PHIL 351]]

9-14-23

### Pre-class reading
#### Cain, Chapter 1 §§4 to end (pp. 19-37) 
[[The Philosophy of Cognitive Science (Cain, Mark J) (Z-Library).pdf]]
##### Core commitments of cognitive science as defined by Cain: 
Cognition, like other science, is governed by laws: 
	*Discover what these laws are*
	*Discover how these laws work*
	*Do so empirically through conjecture and refutation*
	*Postulate (nonphysical) theories to explain observable phenomena*
Duhem-Quine: any theory can be held onto in the face of recalcitrant observational data by making suitable adjustments elsewhere in one's system of commitments
	*Individual sciences are based in commonsense, but in their mature form, depart from it*
##### **Cognitive Revolution (late 1950s-early 1960s)**
Chomsky responds to behaviorism: should be replaced by the study of human's "internal workings" on behavior and learning
	**This idea converges with a few others**: into the discipline of cognitive science
		The mind is populated by *representations*, which are involved in perception and cognition
		Turing: *logic* and mathematics in the processes of thought (removes the problem of the homunculus sitting in the mind and thinking)
		*Metaphysics of the mind*: Functionalism–Putnam's theory– anti-dualist, but also rejects the idea that the mind and brain are 1:1
			"Putnam argued that mental states are Turing machine states. In developing functionalism along these lines, Putnam made clear its affinity with the idea that cognition involves computation and so revealed its value as the metaphysical theory of the mind needed by cognitive science." (34)
		Many of the processes and states involved in cognition are *unconscious* (influence of Freud, Jung, etc.)

##### Conclusion - 
"Cognitive Science" - in 50s and 60s: based around cognition as a form of computation

#### Dietrich et al. (pp. 45-55): "How computer science saved the mind"
[Great Philosophical Objections to Artificial Intelligence](https://gw2jh3xr2c.search.serialssolutions.com/?genre=eBooks&title=Great%20Philosophical%20Objections%20to%20Artificial%20Intelligence&aulast=&aufirst=&date=2021)
Logical Empiricism renders philosophy as a whole meaningless through the reduction of all knowledge to physical and truth-relating (verifiable in fact) principles
-> **Behaviorism** in psychology
	Watson: introduces measurability (and therefore respectability) into psychology
		Mind doesn't exist (*no internal processes exist*)
		All terms describing mind should be replaced with terms describing behavior
		All behavior can be explained by environment only (since mind doesn't exist)
Verificationism self-refutes: it cannot be verified: downfall of logical empiricism
"We know nothing as well as our own consciousness; we are certain we are conscious. So if a philosophical position (Logical Empiricism) rejects consciousness, it is that position that must go." (50)
"Of course, the Behaviourists were well aware of the role of internal physical states. After all, Behaviourists happily awaited a glorious future when the inner workings of the brain would be married to the measurable behaviour of the organisms with those brains. But (digital) computers upset this happy image. **Computers were precisely the undoing of Behaviorism, for they are mechanisms producing complex behavior because of complicated internal states that are not usefully thought of as physical.**"

###### Algorithms and Virtual Machines
What is an algorithm?
> a finite (usually small) set of rules or operations that are precise and unambiguous, and simple to follow (computer scientists use technical terms for these two properties: definiteness, for ‘precise and unambiguous’ and effective, for simple to follow).

> Algorithms, when run on an implementing machine, produce virtual machines. Such machines instantiate different processes. This is a much better way to think of algorithms, and computation in general.

Debunking Behaviorism: 
"Look again at the three central tenets of Behaviourism, and now consider three new tenets:

1. Computer science is not the science of computer behaviour. Clearly inside a computer, a lot of complex processing is going on.
    
2. The behaviour of a virtual machine cannot be described and explained without make reference to internal computational processes (the spell-checking process above, for example).
    
3. Internal states and processes in a computer cannot be eliminated in any way, nor can they be translated completely into ‘behavioural’ concepts. (A lot of what a computer does goes on behind the scenes, and the relevant behaviour doesn’t need to be apparent to the user.)
    

The notion of an internal state is just the notion of an internal representation. When applied to humans, these internal representations are mental representations. And in AI, they are at least quasi-mental representations (see the Third War)." (56)
#### Cantwell-Smith, Chapter 1 (‘Background’) (pp. 1-5)
[[The Promise Of Artificial Intelligence Reckoning And Judgment (Brian Cantwell Smith) (Z-Library).pdf]]

(2 readings mentioned the homunculus problem?)
## Lecture
#### Assessing the Turing test as a test (Dietrich overview)
[[PHIL351 L2 Recognizing intelligence when we see it – Descartes and Turing#Turing Test]]
	**Continued: filling in the details of the test**
**Minimum Turing Test:**
	Trick a *single human at least once* into thinking you're human, after a brief and relaxed text conversation
**Maximum Turing Test:**
	Reliably perform at 70% (Turing's judgement: somewhat arbitrary?) at tricking multiple highly motivated and fairly clever judges into thinking you're human, no matter what searching questions they ask
		Turing thought that computer scientists should not be allowed to judge: unfair to computer (due to intense background knowledge and biases)
	Controversies around modern Turing tests like the Loebner Competition

Considerations: 
	Intentionality
	Consciousness
	Perspective
	Relevance
Note: "artificial" intelligence as we intend to create it now would be *genuine* intelligence, *synthetically* created

**"Carbon Chauvinism"**
	Not only would the computer have to hide its physical appearance during the test (or be hidden), it would have to mask other aspects of itself that reveal it is a computer (i.e. computing too quickly, etc.): *Turing says this deception is in itself a feat of intelligence*
		Holding the computer to an even higher standard! Has to go above and beyond human level of intelligence: prejudicial
		("Act human" vs "act intelligently")

#### Alternative interpretation of the Turing Test (Dietrich cont.)
**The Turing test was never meant to be a test; it was meant to make a point about our definition of intelligence *(that it should be expanded)***
	"Metalinguistic proposal" (regarding the usage of the word "intelligence")

### Defining Intelligence: William James
> "Intelligence is a fixed goal with variable means of achieving it"

#### **Optional reading: Fridland, on James' definition**
Defining characteristics of intelligence
	Goal-directedness
	Appropriateness
	Flexibility
	Transferability
	Manipulability

##### Sphex wasp: false intelligence
How it appears intelligent:
	Behavior is appropriately goal-directed (preps hole for prey, paralyzes prey, returns with prey and checks hole, brings prey in and lays its eggs, babies eat their way out of the paralyzed/preserved prey)
However:
	The behavior is highly inflexible 
		If its sequence is interrupted, it cannot adapt
**Something which is not able to understand how the means lead to the end, despite taking specific deliberate steps**
	The actual behavior of the Sphex is simplified in this example
**Conclusions to draw from the Sphex;**
	Appropriately goal-directed behavior is not intelligent unless it is also flexible (responses are not simply mandated by stimuli but selected from multiple possible responses: "**response freedom**")
	Conversely, flexible response is not intelligent unless it is appropriately goal-directed (randomness is not intelligence)


