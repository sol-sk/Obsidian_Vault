#philosophy 
#cogs 

[[PHIL 351]]

10-26-23

### Pre class reading
Dietrich et al Chapter 5 (pp. 87-134)
### ANNs vs LOT re: Abstract Thinking 
##### Language of Thought: combinatorial 
Semantic constituents are 'isomorphic' to syntactic constituents 
- Each constituent part (A, B, C) can be rearranged
- This is why a thinker who thinks John loves Mary can think that Mary loves John: symbols "Mary" and "John" can be recombined

Common-sense/folk psychology: ascriptions of rational attitudes (beliefs, desires)
- These ascriptions have a structure, which constrains the vehicle (the language of thought)

##### LOT argument against ANNs
1. **If human thought is systematic, then it must have vehicles whose structure maps on to the structure of their contents**
2. **If ANNs are good models of human thought, then human thought cannot have vehicles whose structure maps on to the structure of their contents**
	- Extremely context sensitive, not just discrete, clearly identifiable representation
3. Human thought is systematic
4. Human thought must have vehicles whose structure maps on to the structure of their contents
5. Therefore: Artificial neural networks are not good models of human thought
See Fodor & Pylyshyn

##### ANN advocate response
**Radically: deny that human thought is systematic**
- If this is inconsistent with folk psychology, that's just an argument against folk psychology! We should replace it with something better
-> **"Eliminative materialism"**

**Ramsey, Stich and Garon:**
1. If human thought is systematic, then it must have vehicles whose structure maps on to the structure of their contents
2. If ANNs are good models of human thought, then human thought cannot have vehicles whose structure maps on to the structure of their contents
3. ANNs are good models of human thought
4. Therefore: Human thought cannot have vehicles whose structure maps on to the structure of their contents.
5. (And) Human thought is not systematic

**Grant that human thought is systematic, but deny that systematicity requires vehicle structural mapping**
-> Construct an ANN that exhibits systematicity in its responses!
- Given that this structure finds no echo at the computation level in the structure of connection weights, activation functions, etc. systematicity qualifies as an 'emergent' property of network activity 

**LOT Response**
- Just as easy to train a systematic network as it is unsystematic; systematicity is an *accidental* feature rather than *essential*: ANNs don't explain why systematicity is essential 
- An ANN trained to display systematicity would be implementing LOT: ANNs do not contribute a *computational* explanation, only an implementational explanation

**ANN theorists face a dilhemma:**
- If an ANN can be trained to display systematicity, it vindicates classical approach
- If it cannot, it fails as a general account of human cognition

**Questions for this response:**
- Doesn't this trivialize LOT? 
- Could it be the LOT who is confused about levels of explanation? According to behaviorist theories, prop. attitude psych is not a theory of hidden causes of overt behavior but a description of directly observable behavioral patterns (**Dennett**) â†’ Questions about brain's sub-personal computational architecture are *separate* from system's 'personal' level competences 
	- Architecture of brain just needs to produce requisite behavior
	- Common-sense psych picks up on directly observable behavioral patterns 
	- Computational question of what architecture underlies these is a completely separate issue

