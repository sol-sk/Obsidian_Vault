{"path":"W2023T2/W2023T2 Files/Slides/PSYC218-L12-Regression_part2.pdf","text":"Learning Objectives â€¢ Describe linear regression and construct (fit) linear models to data â€¢ Build equations for simple linear regression and multiple regression â€¢ Calculate and interpret standard error of the estimate â€¢ Contrast r, r2, R, and R2 1 Calculate ğ‘ !|# from raw data ğ‘ !|# = $$!%[âˆ‘ $!%(âˆ‘ $)(âˆ‘ !) ( ]* ++$ &%' \t 2 Night Sleep (X) Grump (Y) X2 Y2 XY 9 7.40 60 54.76 3600 444 24 7.86 56 61.78 3136 440.16 28 6.93 66 48.025 4356 457.38 60 6.22 67 38.688 4489 416.74 99 6.45 55 41.602 3025 354.75 N = 5 Î£ğ‘‹ = 34.86 Î£ğ‘Œ = 304 Î£ğ‘‹2 = 244.855 Î£ğ‘Œ2 = 18606 Î£ğ‘‹ğ‘Œ = 2113.03 55.0 57.5 60.0 62.5 65.0 67.5 6.5 7.0 7.5 Sleep_hrsGrump Calculate Standard Error of the Est. 3 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 (Î£ğ‘Œ)2= 92416 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = 122.8 âˆ’ [2113.03\t âˆ’ 34.86 304 5 ]! 1.811 \t 5\t âˆ’ 2 Calculate ğ‘ $|& 4 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = 122.8 âˆ’ [2113.03\t âˆ’ ğŸğŸğŸğŸ—. ğŸ’ğŸ–ğŸ–]! 1.811 \t ğŸ‘ Calculate ğ‘ $|& 5 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = 122.8 âˆ’ [âˆ’ğŸ”. ğŸ’ğŸ“ğŸ–]! 1.811 \t 3 Calculate ğ‘ $|& 6 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = 122.8 âˆ’ ğŸ’ğŸ. ğŸ•ğŸğŸ” 1.811 \t 3 Calculate ğ‘ $|& 7 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = 122.8 âˆ’ ğŸğŸ‘. ğŸğŸ‘\t 3 Calculate ğ‘ $|& 8 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = ğŸ—ğŸ—. ğŸ•ğŸ• 3 Calculate ğ‘ $|& 9 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 sY|X = ğŸ‘ğŸ‘. ğŸğŸ“ğŸ• Calculate ğ‘ $|& 10 ğ‘ $|& = ''!([âˆ‘ $!% (âˆ‘ $)(âˆ‘ !) ( ] * ++$ )(* \t SSY = Î£ğ‘Œ2 - (,$)* ) N = 5 Î£ğ‘‹= 34.86 Î£ğ‘Œ= 304 Î£ğ‘‹ 2= 1215.22 (Î£ğ‘Œ)2= 92416 Î£ğ‘‹2= 244.855 Î£ğ‘Œ2= 18606 Î£ğ‘‹ğ‘Œ= 2113.03 SSX = 1.811 SSY = 122.8 55.0 57.5 60.0 62.5 65.0 67.5 6.5 7.0 7.5 Sleep_hrsGrumpsY|X = ğŸ“. ğŸ•ğŸ”ğŸ• Homoscedasticity = consistent error (or same scatter) 11 Homoscedasticity = consistent error (or same scatter) 12 Multiple Regression â€¢ Regression model contains 2 or more predictors â€“ Still have only 1 criterion â€¢ Quantitatively, our prediction will always improveâ€¦how would we know? â€“ Standard error of the estimate (sy|x) decreases, orâ€¦ â€“ Multiple coefficient of determination (R2) increases 16 Yâ€™ = bYX + aY Yâ€™ = b1X1 + b2X2 + aY Example: Predicting Happiness â€¢ Two predictors: Income & Optimism 17 Yâ€™happy = b$X$ + bopt.Xopt. + aY r2 = .31 r2 = .23 Trick Question: What is R2 ? R2 in Multiple Regression â€¢ We cannot simply add up the r2 values â€¢ Goal of Prediction: shade as much of the blue circle as possible â€“ Challenge: Predictors might be explaining the same variability 18 R2 in Multiple Regression â€¢ Worst case: Fully redundant predictors â€¢ Goal: shade as much of the blue circle as possible â€“ Challenge: Predictors explaining exact same variability 19 Optimism Income Happiness R2 in Multiple Regression â€¢ Best case: Orthogonal predictors â€¢ Goal: shade as much of the blue circle as possible â€“ Predictors explain unique variability 20 Optimism Income Happiness Symbology Old & New 21 r rs or Ï rpb Ï• Î² = standardized slope coefficient zx, zy ğ‘ = unstandardized slope coefficient Xi, Yi r2 = variability explained by predictor variable R2 = variability explained by regression model R2 Formula: Multiple Regression 22 ğ‘…2 = ğ‘Ÿ$&, * + ğ‘Ÿ$&* * âˆ’ 2(ğ‘Ÿ$&,Ã—ğ‘Ÿ$&*Ã—ğ‘Ÿ&,&*) 1\t âˆ’ ğ‘Ÿ&,&* * Coefficient of Determination: Y ~X1 r2 = Y ~X2 Residual variability of X1 ~ X2 Get rid of parts we double- counted Meehlâ€™s 6th Law of Psychology â€œDamnit; everything correlates with everything else!â€ 23 R2adj. â€¢ If everything correlates with everything elseâ€¦ â€“ Then, every predictor correlates w/criterion to some extent â€“ Some of these correlations will be spurious L â€¢ â€œCrudâ€ is a meaningless correlation â€¢ Results from capitalization on chance â€¢ Adding predictors always increases R2, even crud predictors â€“ R2 adj. is a penalized R2 â€¢ Each new predictor could be crud, so letâ€™s be cautious 24 â€œEverything correlates with everything elseâ€ 25 Another approach to Meehlâ€™s law: **Try** to trash all crud predictors Categorical Predictors in Regression: Sleep, Weather, and Grumpiness 27 Sleep, Weather & Grumpiness ğ‘Œ.= b1X1 + b2X2 + a â€¢ Criterion Y: How grumpy is Dr. Dan? â€¢ Predictor X1: Hours of sleep â€¢ Predictor X2: RainL1 or ShineL2 â€“ b1 = -8.715 â€“ b2 = -1.455 â€“ a = 124.442 â€¢ If rain level of X2 is coded as â€˜1â€™ and shine as â€˜2â€™, then good weather predicts 1.455 fewer grumpy units 2829 40 60 80 100 -2 -1 0 12 dan.sleepdan.grumpRain_or_Shine 1 2 Figure. Regression lines predicting grumpiness by continuous predictor sleep (standardized) and by categorical predictor (rain vs. shine). Level 1: Rain Level 2: Shine Coding Categorical Predictors Yâ€™ = -8.715*X1 + -1.455*X2 + 124.442 â€¢ Criterion Y: How grumpy is Dr. Dan? â€¢ Predictor X1: Hours of sleep â€¢ Predictor X2: RainL1 or ShineL2 â€“ b1 = -8.715 â€“ b2 = -1.455 â€“ a = 124.442 â€¢ What if Dan sleeps 5 hours and itâ€™s raining? 30 Coding Categorical Predictors Yâ€™ = b1X1 + b2X2 + a â€¢ Criterion Y: How grumpy is Dr. Dan? â€¢ Predictor X1: Hours of sleep â€¢ Predictor X2: RainL1, CloudsL2, or ShineL3 â€“ b1 = -8.968 â€“ b2 = ??? â€¢ Estimate 1 and Estimate 2??? â€“ a = 126.178 31 Coding Categorical Predictors â€¢ Criterion Y: How grumpy is Dr. Dan? â€¢ Predictor X1: Hours of sleep â€¢ Predictor X2: RainL1, CloudsL0, or ShineL0 â€“ Dummy variable (for Rain) â€“ b1 = -8.968 â€“ b2 = 0.350 â€“ a = 125.908 â€¢ What is the effect of rain on grumpiness? 32 Coding Categorical Predictors â€¢ Coding of categorical predictors changes interpretation of b â€¢ Dummy coding is most common and simplest method â€¢ Many other coding methods exist depending on hypotheses 33","libVersion":"0.3.2","langs":""}