{"path":"W2023T1/W2023T1 Files/PHIL351 - Lecture 6a.pdf","text":"Classical cognitive science continued P H I L 3 5 1 DR AARON H E N R Y Readings • Same as last time Plan • Review • An outline of the computational theory of mind • Milestones of the classical paradigm in cognitive science Computers and the computational theory of mind • Computers as interpretable automated formal systems • The formalist’s motto: “Take care of the syntax and the semantics will take care of itself” • The ‘dual life’ of a symbol: one syntactic and effective; another semantic and non-effective. • Smith’s Representational Mandate (claims P1-P4) • As a first approximation, the computational theory of mind (or computationalism) asserts that the mind is such a system. Some milestones in classical cognitive science Computational linguistics Poverty of the stimulus and the innateness of universal grammarCartesian linguistics? Computational perception? • AI researchers were initially surprised to learn that perception was a nontrivial task for a cognitive system (see Smith p. 24 on the possible role of Cartesian prejudices here). • Cf. the broadening of ‘cognition’ • The classical solution was to apply to perceptual (mostly, visual) processing the same methodology that Chomsky and others had taken toward language processing. Treat the task computationally! Marr’s tri-level theory of vision Marr couched his computational theory of vision in terms of a hierarchy of levels of analysis: Computational level: What is the computation (the input-output transformation) to be performed? Algorithmic level: How are the computations at the computational level computed? Specifically, what are the representations of the input and output, and the algorithms for their transformation? Implementational level: How are the representations and algorithms at the algorithmic level physically realized or mechanically implemented? Top-down functional analysis “Trying to understand perception by studying only neurons is like trying to understand bird flight by studying only feathers; it just cannot be done. To understand bird flight, you need to understand aerodynamics, only then can one make sense of the structure of feathers and the shape of wings. Similarly, you can’t reach an understanding of why neurons in the visual system behave the way they do, just by studying their anatomy and physiology.” “The nature of the computations that underlie perception depends more upon the computational problems that have to be solved than upon the particular hardware in which their solutions are implemented” (Marr 1982). How do we specify the tasks/functions executed at the computational level? Considerations of overall strategy and rationale. For example: • Question: Why do animals need vision anyway? What is its purpose? What does it accomplish? • Marr’s answer: vision enables the animal to discriminate and recognize objects (as well as their properties and relationships) • Now the animal faces a problem: the retinal state (the ‘evidence’) has many possible causes. • Hence, ‘inverse optics’ is needed. If this is to be computable, we’ll need to break this task down into more specific subtasks. And assumptions are needed at each stage. (The poverty of the stimulus argument again!) brain lesion studies (to learn the brain’s constituent subsystems). ( F R O M M A R R 1 9 8 2 ) 9 / 2 6/2023 13 What is at the ‘top’ of the explanatory hierarchy? So far, we’ve discussed various specialized computations. But what of so-called “general” intelligence – e.g., of the kind that we associate with conscious thinking and reasoning? Newel & Simon’s ‘general problem solver’ (1957) 15 9 / 2 6/2023 Samp le F o o t er Tex t Newel & Simon proposed an analysis of ‘general intelligence’ in terms of problem-solving and means-ends analysis (drawing on human subjects’ explicit self-reports during problem solving) 4 representational elements: representations of current state, goal state, operators, and path constraints. These yield a “search space”. A “problem”: when one’s representation of the initial and goal state differ. A “solution”: a representation of the operation sequence that eliminates the difference consistent with path constraints. Abstract functional analysis of general intelligence in terms of the capacity to select solutions from a search space (i.e., to carry out ‘searches’). Some important insights Most search spaces (even for ‘well- defined’ problems) are vast. To avoid combinatorial explosion, the search must be selective. (Hence, the system must select not only a solution but a search strategy). To be selective, search must use “heuristics.” Whereas a traditional algorithm guarantees success, a heuristic makes success more probable. It does so by pre- specifying which trees should be searched: i.e., by biasing your search toward some options and away from others. Computational tractability introduces fallibility (“no free lunch”). The normative ideal guiding intelligent behaviour: not to optimize but “to satisfice” Contributed to the rise of ‘frames’ and ‘scripts’ as devices for constraining search. 9 / 2 6/2023 Samp le F o o t er Tex t 16 ‘Information processing’ • “The fundamental problem of communication is that of reproducing at one point, either exactly or approximately, a message selected at another point” (Shannon) Broadening Marr’s explanatory framework? Recall our question: “what is cognitive science?” Marr’s multi-level explanatory framework hints at a promising answer: the interdisciplinary endeavour of uncovering, via top-down functional analysis, the computational nature and structure of the (human) mind. The participating fields (psychology, linguistics, computer science, and neuroscience) are unified by a shared conceptual framework, allowing a synoptic, multi-level account of the mind.","libVersion":"0.3.2","langs":""}