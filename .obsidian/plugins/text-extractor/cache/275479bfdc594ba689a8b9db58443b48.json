{"path":"W2023T1/W2023T1 Files/Decision Theory Introduction and Overview.pdf","text":"346 D Decision Theory: An Introduction devices. Analysts can do the same thing by working back- wards, identifying and understanding the business pro- cesses that created their data. Business people are o\u0000en more casual than experimenters about data deﬁnition, so it is critical that data analysts understand the nuance in their data. Second, experimenters build controls into their data collection processes. \u0017e simplest example is calibrating their equipment. Data analysts do not own these processes, but they must understand existing controls and recom- mend others where needed to prevent poor data, whenever possible. \u0017ird, experimenters search for and eliminate 7outliers. When one of us (Redman) worked at Bell Labs in the Šýs and Àýs, we used the expression “rinse, wash, scrub” for increasing eﬀorts to identify and eliminate suspect data. It was intense, manual eﬀort, certainly not feasible for enormous databases. But data analysts can certainly rinse, wash, and scrub a small sample. Doing so provides a basis for evaluating the quality of the entire database. And if the results of a large analysis are conﬁrmed on the scrubbed validating subset, one can proceed with greater conﬁdence. Experimenters are transparent in discussing strengths and weaknesses in their data collection pro- cesses: Data analysts must do so as well. It is the only way to understand the limitations on what they’ve learned. Experimenters recognize they are part of an ongo- ing process: For an experimenter, there is no “ultimate experiment.” A good experiment increases the body of knowledge (even if by saying “there’s nothing of interest here”) and leads to another experiment. Most business data analysts are not engaged in formal science, per se. But they may well be part of an end-to-end innovation pro- cess. Such data analysts should develop an understanding of where they ﬁt and how they can make product devel- opers, marketers, and others more eﬀective. (Note: if your organization doesn’t have such a process, data analysts are well-advised to behave as though it did.) Final Remarks: Taken together, relatively simple actions, quite natural to experimenters, can assist data ana- lysts to better understand their data, know how good their data really are, and improve their overall eﬀectiveness. For learning more about the area of data quality, we recom- mend these books, among many out there, English (ÔÀÀÀ), Huang et al. (ÔÀÀÀ), and Redman (òýýŠ, òýýÔ). Cross References 7Fraud in Statistics 7Misuse of Statistics 7Multi-Party Inference and Uncongeniality References and Further Reading Box GEP (ÔÀÞâ) Science and statistics. J Am Stat Assoc ÞÔ:ÞÀÔ–ÞÀÀ Box GEP, Draper NR (ÔÀŠÞ) Empirical model-building and response surfaces. Wiley, New York English LP (ÔÀÀÀ) Improving data warehouse and business informa- tion quality: methods for reducing costs and increasing profits. Wiley, New York Huang K-T, Lee YL, Wang RY (ÔÀÀÀ) Quality information and knowledge. Prentice Hall, New York Redman TC (òýýÔ) Data quality: the field guide. Butterworth- Heinemann Digital Press, Boston, MA Redman TC (òýýŠ) Data driven: profiting from your most important business asset. Harvard Business School Press, Boston, MA Decision Theory: An Introduction MZ§±ƒŁ Pu±u§«ŽŁ Associate Professor Eindhoven University of Technology, Eindhoven, Netherlands Decision theory (see also 7Decision \u0017eory: An Overview) is the theory of rational decision making. \u0017is is an inter- disciplinary ﬁeld to which philosophers, economists, psy- chologists, computer scientists and statisticians contribute their expertise. It is common to distinguish between nor- mative and descriptive decision theory. Normative decision theory seeks to yield prescriptions about what decision makers are rationally required – or ought – to do. Descrip- tive decision theories seek to explain and predict how people actually make decisions. Descriptive decision the- ory is thus an empirical discipline, which has its roots in experimental psychology. Descriptive and normative deci- sion theory are, thus, two separate ﬁelds of inquiry, which may or may not be studied independently of each other. In decision theory, a decision problem is situation in which a decision maker, (a person, a company, or a soci- ety) chooses what to do from a set of alternative acts, where the outcome of the decision depends on which state of the world turns out to be the actual one. Decision problem are classiﬁed as decisions under risk or ignorance (or uncer- tainty) depending on the information available to the agent at the time at which he makes his choice. In decisions under risk the decision maker knows the probability of the pos- sible outcomes, whereas in decisions under ignorance the probabilities are either unknown or non-existent. \u0017e term uncertainty is either used as a synonym for ignorance, or as a broader term referring to both risk and ignorance. Let us consider an example. Suppose that you are thinking about taking out insurance against the\u0000 of your Decision Theory: An Introduction D 347 D new sports car. Perhaps it costs fçýý to take out insurance on a car worth fÀý,ýýý, and you ask: Is it worth it? In case you know that the probability that the car is stolen is, say, Ô in Ô,ýýý, then you are clearly facing a decision under risk. However, in case you are not able to assess the probabil- ity of the\u0000 then you are on the contrary facing a decision under uncertainty or ignorance. \u0017e most widely applied decision rule for making deci- sions under risk is to apply the principle of maximizing expected value (or utility). According to this decision rule, the total value of an act equals the sum of the values of its possible outcomes weighted by the probability for each outcome. Hence, the expected values of not taking out ﬁre insurance is Ô/Ô,ýýý times the value of losing fòýý,ýýý, whereas the expected value of taking out insurance equals the value of losing fòýý (since the insurance guarantees that you will suﬀer no ﬁnancial loss in case of a ﬁre). Modern decision theory is dominated by attempts to axiomatise the principles of rational decision making, and in particular the principle of maximizing expected utility. (\u0017e term “utility” refers to a technically precise notion of value.) \u0017e ﬁrst axiomatisation was presented by Ramsey in his paper Truth and Probability, written in ÔÀòâ but published posthumously in ÔÀçÔ. Ramsey was a philoso- pher working at Cambridge together with Russell, Moore, and Wittgenstein. In his paper, Ramsey proposed a set of eight axioms for how rational decision makers ought to choose among uncertain prospects. He pointed out that every decision maker behaving in accordance with these axioms will act in a way that is compatible with the princi- ple of maximizing expected value, by implicitly assigning numerical probabilities and values to outcomes. However, it does not follow that the decision maker’s choices were actually trigged by these implicit probabilities and utilities. \u0017is way of thinking about rational decision making is very inﬂuential in the modern literature, and similar ideas were put forward by Savage in \u0017e Foundations of Statistics about two decades later. Another important point of departure in modern deci- sion theory is von Neumann and Morgenstern’s book \u0017eory of Games and Economic Behavior. Von Neumann and Morgenstern showed how a linear measure of value for outcomes (i.e., a utility function) can be generated from a set of axioms dealing with how rational decision mak- ers ought to choose among lotteries. For von Neumann and Morgenstern a lottery is a probabilistic mixture of out- comes; for example, “a ﬁ\u0000y-ﬁ\u0000y chance of winning either fÔýý or a trip to London” is a lottery. \u0017ey showed that every decision maker behaving in accordance with their axioms implicitly behaves in accordance with the princi- ple of maximizing expected utility, and implicitly assigns numerical utilities to outcomes. \u0017e main diﬀerence com- pared to Ramsey’s axiomatisation is that von Neumann and Morgenstern presented no novel theory of probability. \u0017e use of the principle of maximizing expected utility has been criticized by some decision theorists. \u0017e most famous counter argument was proposed by Allais in the ÔÀ€ýs. Consider the following lotteries in which exactly one winning ticket will be drawn at random. Ticket no. 1 Ticket no. 2–11 Ticket no. 12–100 Gamble 1 $1 Million $1 Million $1 Million Gamble 2 $0 $5 Million $1 Million Gamble 3 $1 Million $1 Million $0 Gamble 4 $0 $5 Million $0 In a choice between Gamble Ô and Gamble ò it seems reasonable to choose Gamble Ô since it gives the decision maker fÔ Million for sure, whereas in a choice between Gamble ç and Gamble ¥ many people would feel that it makes sense to trade a ten-in-hundred chance of getting f€ Million, against a one-in-hundred risk of getting noth- ing, and consequently choose Gamble ¥. Several empirical studies have conﬁrmed that most people reason in this way. However, no matter what utility one assigns to money, the principle of maximizing expected utility recommends that the decision maker prefers Gamble Ô to Gamble ò if and only if Gamble ç is preferred to Gamble ¥. \u0017ere is simply no utility function such that the principle of maximizing utility is consistent with a preference for Gamble Ô to Gam- ble ò and a preference for Gamble ¥ to Gamble ç. To see why this is so, we calculate the diﬀerence in expected utility between the two pairs of gambles. Note that the probability that ticket Ô will be drawn is ý.ýÔ, and the probability that one of tickets numbered ò–ÔÔ will be drawn is ý.Ô; hence, the probability that one of tickets numbered Ôò–Ôýý will be drawn is ý.ŠÀ. \u0017is gives the following equations: u (GÔ) − u(Gò) = u (ÔM) − [ý.ýÔu (ýM) + ý.Ôu (€M) + ý.ŠÀu (ÔM)] = ý.ÔÔu (ÔM) − [ý.ýÔu(ý) + ý.Ôu(€M)] (Ô) u (Gç) − u (G¥) = [ý.ÔÔu (ÔM) + ý.ŠÀu (ý)] − [ý.Àu (ýM) + ý.Ôu (€M)] = ý.ÔÔu (ÔM) − [ý.ýÔu (ý) + ý.Ôu (€M)] (ò) 348 D Decision Theory: An Introduction Equations Ô and ò show that the diﬀerence in expected utility between GÔ and Gò is precisely the same as the diﬀerence between Gç and G¥. Hence, no matter what the decision maker’s utility for money is, it is impossi- ble to simultaneously prefer GÔ to Gò and to prefer G¥ to Gç without violating the expected utility principle. How- ever, since many people who have thought very hard about this example still feel it would be rational to stick to the problematic preference pattern described above, there seems to be something wrong with the expected utility principle. Let us now move on to the other type of decision prob- lems mentioned above, viz., decisions under ignorance (or uncertainty). \u0017ere is no single decision rule for decision making under ignorance that is currently widely accepted by decision theorists. However, the maximin rule and the principle of insuﬃcient reason are two of the most inﬂu- ential rules, which have been widely discussed in the lit- erature. \u0017e maximin rule, famously adopted by Rawls, focuses on the worst possible outcome of each alterna- tive. According to this principle, one should maximize the minimal value obtainable with each act. If the worst possible outcome of one alternative is better than that of another, then the former should be chosen. Accord- ing to the principle of insuﬃcient reason, adopted by e.g., Bernoulli and Laplace, it holds that if one has no reason to think that one state of the world is more probable than another, then all states should be assigned equal probabil- ity. A well-known objection to the principle of insuﬃcient reason is that that it seems completely arbitrary to infer that all states are equally probable. If one has no reason to think that one state is more probable than another, it seems strange to conclude anything at all about probabili- ties. Or, alternatively put, if one has no reason to think that some state is twice as probable as another, why not then rea- son as if that state is twice as probable as the other? Every possible distribution of probabilities seems to be equally justiﬁed. However, not every decision problem can be classiﬁed as being either a decision under risk or a decision under ignorance. A major sub-ﬁeld of modern decision theory is so-called multi-attribute approaches to decision the- ory. \u0017e diﬀerence between single- and multi-attribute approaches is that in a single-attribute approach, all out- comes are compared on a single utility scale. For example, in a decision between saving a group of ﬁshermen from a sinking ship at a cost of one million dollars or letting the ﬁshermen die and save the money, the value of a human life will be directly compared with monetary outcomes on a single scale. However, many authors think that such direct comparisons between the value of a human life and money makes no sense – i.e., that human life and money are incommensurable. \u0017e multi-attribute approach seeks to avoid the crit- icism that money and human welfare are incommensu- rable by giving up the assumption that all outcomes have to be compared on a common scale. In a multi-attribute approach, each type of attribute is measured in the unit deemed to be most suitable for that attribute. Perhaps money is the right unit to use for measuring ﬁnancial costs, whereas the number of lives saved is the right unit to use for measuring human welfare. \u0017e total value of an alternative is therea\u0000er be determined by aggregating the attributes, e.g., money and lives, into an overall ranking of the available alternatives. Here is an example. Mary has somehow divided the relevant objectives of her decision problem into a list of attributes. For illustrative purposes, we assume that the attributes are (a) the number of lives saved, (b) the ﬁnan- cial aspects of the decision, (c) the political implications of the decision, and (d) the legal aspects of the decision. Now, to make a decision, Mary has to gather information about the degree to which each attribute can be realized by each alternative. Consider the following table, in which we list four attributes and three alternatives. Attribute 1 Attribute 2 Attribute 3 Attribute 4 Alt. a1 1 3 1 2 Alt. a2 3 1 3 1 Alt. a3 2 2 2 2 \u0017e numbers represent the degree to which each attribute is fulﬁlled by the corresponding alternative. For example, in the le\u0000most column the numbers show that the second alternative fulﬁlls the ﬁrst attribute to a higher degree than the ﬁrst alternative, and so on. So far the rank- ing is ordinal, so nothing follows about the “distance” in value between the numbers. However, in many applica- tions of the multi-attribute approach it is of course natural to assume that the numbers represent more than an ordinal ranking. \u0017e number of people saved from a sinking ship can, for instance, be measured on a ratio scale. \u0017is also holds true of the amount of money saved by not rescuing the ﬁshermen. In this case, nothing prevents the advocate of the multi-attribute approach to use a ratio or interval scale if one so wishes. Several criteria have been proposed for choosing among alternatives with multiple attributes. It is common to distinguish between additive and non-additive criteria. Additive criteria assign weights to each attribute, and rank Decision Theory: An Overview D 349 D alternatives according to the weighted sum calculated by multiplying the weight of each attribute with its value. \u0017e weights are real numbers between zero and one, which together sum up to one. Obviously, this type of criterion makes sense only if the degree to which each alternative satisﬁes any given attribute can be represented at least on an interval scale, i.e., if it makes sense to measure value in quantitative terms. Let us, for the sake of the argument, suppose that this is the case for the numbers in table above, and suppose that all attributes are assigned equal weights, i.e., Ô~¥. \u0017is implies that the value of alternative aÔ is Ô~¥ ⋅ Ô + Ô~¥ ⋅ ç + Ô~¥ ⋅ Ô + Ô~¥ ⋅ ò = Þ~¥. Analogous cal- culations show that the value of aò is ò, while that of aç is also ò. Since we deﬁned the ranking by stipulating that a higher number is better than a lower, it follows that aò and aç are better than aÔ. Another major sub-ﬁeld of contemporary decision the- ory is social choice theory. Social choice theory seeks to analyze collective decision problems: How should a group aggregate the preferences of its individual members into a joint preference ordering? In this context, a group could be any constellation of individuals, such as a married couple, a number of friends, the members of a club, the citizens of a state, or even all conscious beings in universe. A social choice problem is any decision problem faced by a group, in which each individual is willing to state at least ordi- nal preferences over outcomes. Once all individuals have stated such ordinal preferences we have a set of individ- ual preference orderings. \u0017e challenge faced by the social decision theorist is to somehow combine the individual preference ordering into a social preference ordering, that is, a preference ordering that reﬂects the preferences of the group. A social state is the state of the world that includes everything that individuals care about, and the term social welfare function (SWF) refers to any decision rule that aggregates a set of individual preference orderings over social states into a social preference ordering over those states. \u0017e majority rule used in democratic elections is an example of a SWF. \u0017e most famous technical result in social choice the- ory is Arrow’s impossibility theorem, according to which there is no SWF that meets a set of relatively weak nor- mative conditions. A natural interpretation is that social decisions can never be rationally justiﬁed, simply because every possible mechanism for generating a social prefer- ence ordering – including the majority rule – is certain to violate at least one of Arrow’s conditions. \u0017is result received massive attention in academic circles, and in the ÔÀâýs and Þýs, many people took the theorem to prove that “democracy is impossible”. However, the present view is that the situation is not that bad. By giving up or modifying some of Arrow’s conditions one can formulate coherent SWFs that are not vulnerable to his impossibility result. Today, the theorem is interesting mainly because it opened up an entirely new ﬁeld of inquiry. Cross References 7Bayesian Statistics 7Decision \u0017eory: An Overview 7Imprecise Probability 7Loss Function 7Multicriteria Decision Analysis 7Multiple Statistical Decision \u0017eory 7Philosophical Foundations of Statistics 7Statistics and Gambling References and Further Reading Allais M (ÔÀ€ç) Le comportement de l’homme rationnel devant le risque: critique des postulates et axiomes de l’ecole Américaine. Econometrica òÔ:€ýç–€¥â Arrow KJ (ÔÀ€Ô) Social choice and individual values, ònd edn (ÔÀâç). Wiley, New York Kahneman D, Tversky A (ÔÀÞÀ) Prospect theory: an analysis of decisions under risk. Econometrica ¥Þ:òâç–òÀÔ Peterson M (òýýÀ) An introduction to decision theory. Cambridge University Press, Cambridge Ramsey FP (ÔÀòâ) Truth and Probability, Ramsey, ÔÀçÔ. In: Braith- waite RB (ed) The foundations of mathematics and other logical essays, Ch. VII. Kegan Paul, London, pp Ô€â–ÔÀŠ Savage LJ (ÔÀ€¥) The foundations of statistics, ònd edn (ÔÀÞò, Dover). Wiley, New York Trench, Trubner & Co., Harcourt, Brace and Company, New York von Neumann J, Morgenstern O (ÔÀ¥Þ) Theory of games and economic behavior, ònd edn. Princeton University Press (Ôst edn without utility theory) Decision Theory: An Overview SêuŁ Oêu HZŁ««ŽŁ Professor and Head Royal Institute of Technology, Stockholm, Sweden Decision theory (see also 7Decision \u0017eory: An Introduc- tion) is the systematic study of goal-directed behavior under conditions when diﬀerent courses of action (options) can be chosen. \u0017e focus in decision theory is usually on the out- come of decisions as judged by pre-determined criteria or, in other words, on means-ends rationality. Decision theory has developed since the middle of the twentieth century through contributions from several academic disciplines. In this overview over fundamental decision theory, the 350 D Decision Theory: An Overview focus will be on how decisions are represented and on decision rules intended to provide guidance for decision- making. Finally two paradoxes will be presented in order to exemplify the types of issues that are discussed in modern decision theory. The Representation of Decisions \u0017e standard representation of a decision problem requires that we specify the alternatives available to the decision- maker, the possible outcomes of the decision, the values of these outcomes, and the factors that have an inﬂuence on the outcome. Alternatives To decide means to choose among diﬀerent alternatives (options). In some decision problems, the set of alterna- tives is open in the sense that new alternatives can be invented or discovered by the decision-maker. A typical example is your decision how to spend tomorrow evening. In other decision problems, the set of alternatives is closed so that no new alternatives can be added. Your decision how to vote in the upcoming elections will probably be an example of this. \u0017ere will be a limited number of alternatives (candidates or parties) between which you can choose. In real life, many if not most decisions come with an open set of alternatives. In decision theory, however, alter- native sets are commonly assumed to be closed. \u0017e reason for this is that closed decision problems are much more accessible to theoretical treatment. If the alternative set is open, a deﬁnitive solution to a decision problem is not in general available. In informal deliberations about decisions, we o\u0000en refer to alternatives that can be combined with each other. Hence, when deciding how to spend tomorrow evening you may begin by choosing between eating out and going to the cinema, but end up deciding to do both. In decision theory, the alternatives are assumed to be mutually exclu- sive, i.e., no two of them can both be realized. However, this diﬀerence is not very important since you can always convert a set of compatible alternatives to a set of mutually exclusive ones. \u0017is is done by listing all the possible com- binations (in this example: eating out and not going to the cinema, eating out and going to the cinema, etc.). States of Nature \u0017e eﬀects of a decision depend not only on what choice the decision-maker makes, but also on various fac- tors beyond the decision-maker’s control. Some of these extraneous factors constitute background information that the decision-maker has access to. Others are unknown. \u0017ey may depend, for instance, on the actions of other persons and various natural events. In decision theory, it is common to summarize the var- ious unknown extraneous factors into a number of cases, called states of nature. \u0017e states of nature include decisions by other persons. \u0017is is a major diﬀerence between deci- sion theory and game theory. In game theory, decisions by several persons that may compete or cooperate are treated on a par with each other in the formal representation. In decision theory, the focus is on one decision-maker, and the actions and choices of others are treated diﬀerently, namely in the same way as natural events. As an example, consider a young boy, Peter, who makes up his mind whether or not to go to the local soccer ground to see if there is any soccer going on that he can join. \u0017e eﬀect of that decision depends on whether there are any soccer players present. In decision theory, this situation is described in terms of two states of nature, “players present” and “no players present.” Outcomes \u0017e possible outcomes of a decision are determined by the combined eﬀects of a chosen alternative and the state of nature that materializes. Hence, if Peter goes to the soccer ground and there are no players present, then the outcome can be summarized as “walk and no soccer,” if he goes and there are players present then the outcome is “walk and soccer,” and if he does not go then the outcome is “no walk and no soccer.” Decision Matrices \u0017e alternatives, the states of nature, and the resulting out- comes in a decision can be represented in a decision matrix. A decision matrix is a table in which the alternatives are represented by rows and the states of nature by columns. For each alternative and each state of nature, the decision matrix assigns an outcome (such as “walk, no soccer” in our example). \u0017e decision matrix for Peter’s decision is as follows: No soccer players Soccer players Go to soccer ground Walk, no soccer Walk, soccer Stay home No walk, no soccer No walk, no soccer Such a matrix provides a clear presentation of the deci- sion, but it does not contain all the information that the decision-maker needs to make the decision. \u0017e most important missing information concerns how the out- comes are valued. Decision Theory: An Overview D 351 D Value Representation When we make decisions, or choose among options, we try to obtain as good an outcome as possible, accord- ing to some standard of what is good or bad. \u0017e choice of a value-standard for decision-making is usually not considered to fall within the subject matter of decision theory. Instead, decision theory assumes that such a stan- dard is available from other sources, perhaps from moral philosophy. \u0017ere are two major ways to express our evaluations of outcomes. One of these is relational representation. It is expressed in terms of the three comparative value notions, namely “better than” (strong preference, >), “equal in value to” (indiﬀerence, ≡), and “at least as good as” (weak prefer- ence, ≥). \u0017ese three notions are interconnected according to the following two rules: Ô. A is better than B if and only if A is at least as good as B but B is not at least as good as A. (A > B if and only if A ≥ B and not B ≥ A.) ò. A is equally good as B if and only if A is at least as good as B and B is at least as good as A. (A ≡ B if and only if A ≥ B and B ≥ A.) \u0017e other major method to express our evaluations of out- comes is numerical representation. It consists in assigning numbers to the possible outcomes; such that an outcome has a higher number than another if and only if it is pre- ferred to it. In an economic context, willingness to pay is o\u0000en used as a measure of value. If a person is prepared to pay, say f€ýý for a certain used car and fò€ý for another, then these sums can be used to express her (economic) valuation of the two vehicles. However, not all values are monetary. According to some moral theorists, all values can instead be reduced to one unit of measurement, utility. \u0017is entity may or may not be identiﬁed with units of human happiness. According to utilitarian moral theory, decision-makers should, at least in principle, always (try to) maximize total utility. Decision theorists o\u0000en use numerical values as abstract tools in the analysis of decisions. \u0017ese values may be taken to represent utilities, but only in a rather abstract sense since they are not based on any method to measure utilities. Once we have a numerical representation of value, we can replace the verbal descriptions of outcomes in a deci- sion matrix by these values. In our example, suppose that Peter likes to play soccer but does not like walking to the soccer ground and back home. \u0017en his utilities may be representable as follows: No soccer players Soccer players Go to soccer ground 0 10 Stay home 3 3 Mainstream decision theory is almost exclusively devoted to problems that can be expressed in matrices of this type, utility matrices (payoﬀ matrices). Probability or Uncertainty Decisions are o\u0000en categorized according to how much the decision-maker knows beforehand about what state of nature will in fact take place. In an extreme case, the decision-maker knows for sure which state of nature will obtain. If, in the above example, Peter knows with certainty that there are players at the soccer ground, then this makes his decision very simple. \u0017e same applies if he knows that there are no players. Cases like these, when only one state of nature needs to be taken into account, are called decision-making under certainty. Non-certainty is usually divided into two categories, called risk and uncertainty. A decision is made under risk if it is based on exact probabilities that have been assigned to the relevant states of nature; otherwise it is made under uncertainty. Decisions at the roulette table are good exam- ples of decisions under risk since the probabilities are known (although some players do not pay much attention to them). A decision whether to marry is a good example of a decision under uncertainty. \u0017ere is no way to deter- mine the probability that a marriage will be successful, and presumably few prospective brides or grooms would wish to base their decision on precise probability estimates of marital success or failure. In some cases, we do not even have a full list of the relevant states of aﬀairs. Hence, decisions on the introduc- tion of a new technology have to be made without full knowledge of the possible future social states in which the new technology will be used. Such cases are referred to as decision-making under great uncertainty, or ignorance. \u0017is adds up to the following scale of knowledge situations in decision problems: Certainty It is known what states of nature will occur Risk The states of nature and their probabilities are known Uncertainty The states of nature are known but not their probabilities Great uncertainty, ignorance Not even the states of nature are known 352 D Decision Theory: An Overview \u0017e probabilities referred to in decision theory may be either objective or subjective. In some applications, reli- able estimates of probabilities can be based on empirically known frequencies. As one example, death rates at high exposures to asbestos are known from epidemiological studies. In most cases, however, the basis for probabil- ity estimates is much less secure. \u0017is applies for instance to failures of a new, as yet untried technological device. In such cases we have to resort to subjective estimates of the objective probabilities. Some decision theorists deny the existence of true objective probabilities and regard all probabilities as expressions of degrees of belief, which are of course strictly subjective. In cases when exact probabilities are not known, uncer- tainty can be expressed with various, more complex mea- sures. Binary measures: \u0017e probability values are divided into two groups, possible and impossible values (or attention-worthy and negligible values). Usually, the for- mer form a single interval. \u0017en the uncertainty can be expressed in terms of an interval, for instance: “\u0017e prob- ability of a nuclear war in the next thirty years is between Ôý and ò€ per cent.” Multivalued measures: A numerical measure is used to distribute plausibility over the possible probability val- ues. \u0017is measure may (but need not) be a (second-order) probability measure. \u0017en, instead of just saying that the probability is between Ôý% and ò€%, we can say that there is a €% probability that the probability is between ÔÞ% and ÔŠ%, a ¥% probability that it is between ÔŠ% and ÔÀ%, etc. Robustness measures: \u0017e more certain we are about a probability, the less willing we are to change our estimate of it. \u0017erefore, willingness to change one’s estimate of a probability when new information arrives can be used as a measure of uncertainty. Decision Rules Decision theorists have developed a series of decision rules, intended to ensure that decisions are made in a systematic and rational way. The Maximin Rule Among the decision rules that are applicable without numerical information, the maximin rule is probably the most important one. For each alternative, we deﬁne its security level as the worst possible outcome with that alter- native. \u0017e maximin rule urges us to choose the alternative that has the highest security level. In other words, we maximize the minimal outcome. \u0017e maximin rule has o\u0000en, and quite accurately, been described as a cautious rule. It has also been described as pessimistic, but that is an unfortunate terminology, since caution and pessimism are quite independent of each other. As an example of the maximin rule, consider the following variant of the soccer example from above: No soccer players Soccer players Go to soccer ground Walk, no soccer Walk, soccer Stay home No walk, no soccer No walk, no soccer \u0017e preferences are: Walk, soccer is better than No walk, no soccer is better than Walk, no soccer \u0017e security level of Stay home is “no walk, no soccer” whereas that of Go to soccer ground is “walk, no soccer”. Since the former is better than the latter, in order to max- imize the security level, Peter would have to stay at home. Consequently, this is what the maximin rule recommends him to do. Even though the maximin rule can be applied to rela- tional value information as above, it is easier to apply if the value information is presented in numerical form. Again, consider the following utility matrix: No soccer players Soccer players Go to soccer ground 0 10 Stay home 3 3 Here, the security level of Stay home is ç whereas that of Go to soccer ground is ý. Since ç is larger than ý, the maximin rule recommends Peter to stay at home, just as in the relational presentation of the same example. The Maximax Rule \u0017e best level that we can at all obtain if we choose a cer- tain alternative is called its hope level. According to the maxi-max rule, we should choose the alternative whose hope level (best possible outcome) is best. Just like the maxi-min rule, the maxi-max rule can be applied even if we only have relational (non-numerical) value informa- tion. Consider again the soccer example. \u0017e hope level of Decision Theory: An Overview D 353 D Stay home is “no walk, no soccer,” and that of Go to soccer ground is “walk, soccer” that Peter values higher. Hence, the maximax rule urges Peter to go to the soccer ground. Similarly, in the numerical representation, Stay home has the hope level ç and Go to soccer ground has Ôý; hence again Peter is advised to go to the soccer ground. \u0017e maximax rule has seldom been promoted. Con- trary to the maximin rule, it is o\u0000en conceived as irrational or as an expression of wishful thinking. It is indeed hardly commendable as a general rule for decision-making. How- ever, in certain subareas of life, taking chances may be beneﬁcial, and in such areas behavior corresponding to the maximax rule may not be irrational. Life would probably be much duller unless at least some of us were maximaxers on at least some occasions. The Cautiousness Index \u0017ere is an obvious need for a decision criterion that does not force us into the extreme cautiousness of the maximin rule or the extreme incautiousness of the maximax rule. A middle road is available, but only if we have access to numerical information. We can then calculate a weighted average between the security level and the hope level, and use this weighted average to rank the alternatives. Let us again consider the numerical presentation of the soccer example: No soccer players Soccer players Go to soccer ground 0 10 Stay home 3 3 For each alternative A, let min(A) be its security level and max(A) its hope level. In our example, min(Go to soccer ground) = ý and max(Go to soccer ground) = Ôý. If we choose to assign equal weight to the security level and the hope level, then the weighted value of Go to soccer ground is ý.€ × ý + ý.€ × Ôý = €. Since min(Stay home) = max(Stay home) = ç, the weighted average value of Stay home is ç. Hence, with these relative weights, Peter is recommended to go to the soc- cer ground. More generally speaking, each alternative A is assigned a value according to the following formula: α × min (A) + (Ô − α) × max (A) If α = Ô, then this rule reduces to the maximin criterion and if α = ý, then it reduces to the maximax criterion. \u0017e index α is o\u0000en called the Hurwicz α index, a\u0000er economist Leonid Hurwicz who proposed it in ÔÀ€ý. It is also o\u0000en called the optimism-pessimism index, but the latter ter- minology should be avoided since the index represents the degree of (un)cautiousness rather than that of opti- mism. It can more appropriately be called the cautiousness index. Minimax Regret Utility information also allows for another decision crite- rion that puts focus on how an outcome diﬀers from other outcomes that might have been obtained under the same state of aﬀairs, if the decision-maker had chosen another alternative. In our example, if Peter stays home and there are players at the soccer ground, then he has made a loss that may give rise to considerable regret. If he goes to the soccer ground and there is no one there to play with him, then he has also made a loss, but a smaller one. \u0017e deci- sion rule based on these considerations is usually called the minimax regret criterion. It also has other names, such as minimax risk, minimax loss, and minimax. In this decision rule the degree of regret is measured as the diﬀerence between the utility obtained and the high- est utility level that could have been obtained (in the same state of the world) if another alternative had been chosen. A regret matrix can quite easily be derived from a utility matrix: Replace each entry by the number obtained by sub- tracting it from the highest utility in its column. In our example, the regret matrix will be as follows: No soccer players Soccer players Go to soccer ground 3 0 Stay home 0 7 \u0017e minimax regret criterion advices the decision- maker to choose the option with the lowest maximal regret (to minimize maximal regret). In this case it recommends Peter to go to the soccer ground. Just like the maximin rule, the minimax regret rule can be described as cautious, but they apply cautiousness to diﬀerent aspects of the decision (the value of the actual outcome respectively its regrettableness). As this example shows, they do not always yield the same recommendation. Expected Utility None of the above decision rules requires or makes use of probabilistic information. When probabilities are avail- able, the dominating approach is to maximize expected utility (EU). \u0017en to each alternative is assigned a weighted average of its utility values under the diﬀerent states of nature, with the probabilities of these states used as weights. 354 D Decision Theory: An Overview In the above example, suppose that based on previ- ous experience Peter believes the probability to be ý.¥ that there are players at the soccer ground. We can enter the probabilistic information into the column headings of the utility matrix as follows: No soccer players Probability 0.6 Soccer players Probability 0.4 Go to soccer ground 0 10 Stay home 3 3 \u0017e expected (probability-weighted) utility of going to the soccer ground is ý.â × ý + ý.¥ × Ôý = ¥, and that of staying at home is ý.â × ç + ý.¥ × ç = ç. If Peter wants to maximize expected utility then he should, in this case, go to the soccer ground. Obviously, the recommendation would be diﬀerent with other probabilities. For a general formula representing expected utility, let there be n outcomes, to each of which is associated a util- ity and a probability. \u0017e outcomes are numbered, so that the ﬁrst outcome has utility uÔ and probability pÔ, the sec- ond has utility uò and probability pò, etc. \u0017en the expected utility is deﬁned as follows: pÔ × uÔ + pò × uò + . . . + pn × un Expected utility maximization based on subjective prob- abilities is commonly called Bayesian decision theory, or Bayesianism. (\u0017e name derives from \u0017omas Bayes, ÔÞýò– ÔÞâÔ, who provided much of the mathematical foundations for probability theory). According to Bayesianism, a ratio- nal decision-maker should have a complete set of proba- bilistic beliefs (or at least behave as if she had one) and all her decisions should take the form of choosing the option with the highest expected utility. Two Paradoxes of Decision Theory Much of the modern discussion on decision theory has been driven by the presentation of paradoxes, i.e., sit- uations in which decision-making criteria that seem to epitomize rationality nevertheless give rise to decisions that are contrary to most people’s intuitions. \u0017e follow- ing two decision paradoxes serve to exemplify the kinds of philosophical problems that are discussed in the decision- theoretical research literature. Ellsberg’s Paradox Daniel Ellsberg has presented the following decision prob- lem: We have an urn that contains çý red ball and âý balls that are either black or yellow. \u0017e distribution between the latter two colors is unknown. A ball is going to be drawn at random from the urn. Before that is done you are oﬀered bets by two persons. Anne oﬀers you to bet either on red or on black. If you bet on red, then you will receive e Ôýý if the drawn ball is red and nothing if it is either black or yellow. Similarly, if you bet on black, then you will get e Ôýý if the ball is black, and nothing if it is red or yellow. Betty oﬀers you to bet either on red-or-yellow or on black-or-yellow. If you bet on red-or-yellow, then you will get e Ôýý if the drawn ball is either red or yellow, but noth- ing if it is black. If you bet on black-or-yellow, then you will get e Ôýý if the drawn ball is either black or yellow, but nothing if it is red. Most people, it turns out, prefer betting red to betting black, but they prefer betting black-or-yellow to betting red-or-yellow. It is fairly easy to show that this pattern is at variance with expected utility maximization, i.e., there is no way to assign utilities that would make this pat- tern compatible with the maximization of expected utility. Ellsberg’s own conclusion was that decision-making must take into account factors not covered by probabilities and utilities, in particular the degree of uncertainty of the various probability estimates. Another problem with this pattern is that it violates the sure-thing principle that is a much acclaimed rational- ity criterion for decisions. To introduce the principle, let A and B be two alternatives, and let S be a state of nature such that the outcome of A in S is the same as that of B. In other words, the outcome in case of S is a “sure thing,” not inﬂuenced by the choice between A and B. \u0017e sure-thing principle says that if the “sure thing” (i.e., the common out- come in case of S) is changed, but nothing else is changed, then the choice between A and B is not aﬀected. As an example, suppose that a whimsical host wants to choose a dessert by tossing a coin. You are invited to choose between alternatives A and B. In alternative A, you will have fruit in case of heads and nothing in case of tails. In alternative B you will have pie in case of heads and nothing in case of tails. \u0017e decision matrix is as follows: Heads Tails A Fruit Nothing B Pie Nothing When you have made up your mind and announced which of the two alternatives you prefer, the whimsical host suddenly remembers that he has some ice cream, and Decision Theory: An Overview D 355 D changes the options so that the decision matrix is now as follows: Heads Tails A Fruit Ice cream B Pie Ice cream Since only a “sure thing” (an outcome that is common to the two alternatives) has changed between the two deci- sion problems, the sure-thing principle demands that you do not change your choice between A and B when the deci- sion problem is revised in this fashion. If, for instance, you chose alternative A in the ﬁrst decision problem, then you are bound to do so in the second problem as well. In this example, the sure-thing principle appears ratio- nal enough, and it would seem natural to endorse it as a general principle for decision-making. Ellsberg’s paradox shows that is not quite as self-evident as it may seem to be at ﬁrst sight. Newcomb’s Paradox \u0017e following paradox was proposed by the physicist William Newcomb: In front of you are two boxes. One of them is transparent, and you can see that it contains fÔ,ýýý. \u0017e other is covered, so that you cannot see its con- tents. It contains either fÔ,ýýý,ýýý or nothing. You have two options to choose between. One is to take both boxes, and the other is to take only the covered box. A predictor who has infallible (or almost infallible) knowledge about your psyche has put the million in the covered box if he predicted that you will only take that box. Otherwise, it is empty. Let us apply maximized expected utility to the prob- lem. If you decide to take both boxes, then the predictor has almost certainly foreseen this and put nothing in the covered box. Your gain is fÔ,ýýý. If, on the other hand, you decide to take only one box, then the predictor has fore- seen this and put the million in the box, so that your gain is fÔ,ýýý,ýýý. In other words, maximization of expected utility urges you to take only the covered box. \u0017ere is, however, another plausible approach to the problem that leads to a diﬀerent conclusion. If the predic- tor has put nothing in the covered box, then it is better to take both boxes than to take only one, since you will gain fÔ,ýýý instead of nothing. If he has put the million in the box, then too it is better to take both boxes, since you will gain fÔ,ýýÔ,ýýý instead of fÔ,ýýý,ýýý. \u0017us, taking both boxes is better in all states of nature. (It is a dominating option.) It seems to follow that you should take both boxes, contrary to the rule of maximizing expected utilities. \u0017e two-box strategy in Newcomb’s problem maxi- mizes the “real gain” of having chosen an option, whereas the one-box strategy maximizes the “news value” of having chosen an option. \u0017e very fact that a certain decision has been made in a certain way changes the probabilities that have to be taken into account in that decision. In causal decision theory, expected utility calcula- tions are modiﬁed so that they refer to real value rather than news value. \u0017is is done by replacing standard probabilities by some formal means for evaluating the causal implications of the diﬀerent options. Since there are several competing philosophical views of causality, there are also several formulations of causal decision theory. About the Author Sven Ove Hansson is professor in philosophy and Head of the division of Philosophy, Royal Institute of Technology, Stockholm. He is Editor-in-Chief of \u0017eoria. His research areas include value theory, decision theory, epistemology, belief dynamics and the philosophy of probability. He is the author of well over òýý articles in refereed journals. His books include A Textbook of Belief Dynamics. \u0017e- ory Change and Database Updating (Kluwer ÔÀÀÀ) and \u0017e Structures of Values and Norms (CUP òýýÔ). He is a mem- ber of the Royal Swedish Academy of Engineering Sciences (IVA). Cross References 7Bayesian Statistics 7Decision \u0017eory: An Introduction 7Imprecise Probability 7Loss Function 7Multicriteria Decision Analysis 7Multiple Statistical Decision \u0017eory 7Philosophical Foundations of Statistics 7Statistical Inference for Quantum Systems 7Statistics and Gambling References and Further Reading Gärdenfors P, Sahlin NE (eds) (ÔÀŠŠ) Decision, probability, and utility. Cambridge University Press, Cambridge Hansson SO (òýý€) Decision theory. A brief introduction. http://www.infra.kth.se/~soh/decisiontheory.pdf Luce RD, Raiffa H (ÔÀ€Þ) Games and decisions: introduction and critical survey. Wiley, New York Resnik MD (ÔÀŠÞ) Choices – an introduction to decision theory. University of Minnesota Press, Minneapolis","libVersion":"0.3.2","langs":""}