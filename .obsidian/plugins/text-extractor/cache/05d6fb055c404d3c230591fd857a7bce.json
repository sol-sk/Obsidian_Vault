{"path":"W2023T2/W2023T2 Files/Slides/annotated-COGS300-L10-deep_learning.pdf","text":"COGS300 Deep Learning Instructor: Márton Sóskuthy marton.soskuthy@ubc.ca TAs: Daichi Furukawa · Victoria Lim · Amy Wang cogs.300@ubc.ca Is this a symbol system or a connectionist system? implements implements 3 Marr’s levels of analysis implementational level algorithmic/representational level computational level what does the system do? goals? representations / processes? physical implementation? 4 Marr’s levels of analysis implementational level algorithmic/representational level computational level what does the system do? goals? representations / processes? physical implementation? 56 https://www.asimovinstitute.org/ neural-network-zoo/ Connectionist networks (2019) Connectionist networks Fully Connected (Feed Forward) 7 Deep Fully Connected (Feed Forward) 8 Connectionist networksConnectionist networks https://adamharley.com/nn_vis/ 10 Distributed representations “2” 11 Superpositional representations 12 Superpositional representationsSubsymbolic representations 13 Subsymbolic representations 14 Subsymbolic representations 15 Subsymbolic representations 1617 Graceful degradation 18 Graceful degradation I’m still OK! 19 Connectionist networks Convolutional Network convolution pooling & convolution pooling & convolution “it’s a face!” https://www.youtube.com/watch?v=FmpDIaiMIeA 20 Connectionist networks Convolutional Network ConvolutionConvolutionConvolutionConvolutionConvolutionConvolutionConvolutionConvolutionPoolingPoolingPoolingPoolingPoolingPooling Convolution Pooling … … … … … … “1” “2” “3” “4” “5” … … … … … … “1” “2” “3” “4” “5” https://adamharley.com/nn_vis/ 38 Connectionist networks Recurrent network Let’s start by taking stock of what we’ve learnt about connectionism so far… • the perceptron • the perceptron learning rule • linear separability • limitations of single-layer perceptrons • multi-layer neural networks • gradient descent • distributed representations • fully connected, convolutional, recurrent network Revision 39 Bad robots! 40 CycleGAN link CycleGAN: a deep neural network for converting images from one domain into another 41 CycleGAN CycleGAN does this without relying on paired images 42 CycleGAN ﬁrst network: learns conversion G(x) from domain A to domain B G(x) 43 CycleGAN second network: tries to tell if G(x) is a ‘fake’ or a real image from Y vs. 44 CycleGAN but, at this point, x could in principle be translated into *any* image from Y: 45 CycleGAN third network: learns conversion F(y) from domain Y to domain X F(G(x)) 46 CycleGAN the whole AI is constrained to minimise the diﬀerence between x and F(G(x)) diﬀ( x, F(G(x)) ) 47 A connectionist network for creating maps link CycleGAN 48 A connectionist network for creating maps link CycleGAN 49 “But in fact this occurrence, far from illustrating some kind of malign intelligence inherent to AI, simply reveals a problem with computers that has existed since they were invented: they do exactly what you tell them to do.” source: TechCrunch, link 50","libVersion":"0.3.2","langs":""}