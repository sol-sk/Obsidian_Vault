{"path":"W2023T2/W2023T2 Files/Readings/kelso-ch1.pdf","text":"• * How Nature Handles Complexity O * Nature uses only the longest threads to weave her pattern, so each small piece of the fabric reveals the organization of the entire tapestry. —R. P. Feynman People are called creative or crazy when they see a likeness between things that were thought not to be alike before. Creativity, however, entails more than seeing a likeness or drawing a metaphor. Abstracting something new is what matters. The examples that I will talk about in this chapter and the concepts that emerge from them initially will seem very strange and far removed from what we are really trying to understand, the behavior of hu- mans. But I hope to show later on that the concepts and tools introduced here actually provide the foundation for a theory of how mind, brain, and behavior are related. At the heart of this theory is how patterns are formed in complex systems. I view the brain not as a box with compartments that contain sad- ness, joy, color, texture, and all the other \"objects\" and categories that one might think of. Instead, I envisage it as a constantly shifting dynamic system; more like the flow of a river in which patterns emerge and disappear, than a static landscape. \"Meaningful patterns,\" as Sherrington said over fifty years ago, \"but never abiding ones.\"1 This is an entirely different image from the brain as a computer with stored contents or subroutines to be called up by a program. In nature's pattern-forming systems, contents aren't contained any- where but are revealed only by the dynamics. Form and content are thus inextricably connected and can't ever be separated.2 Like a river whose eddies, vortices, and turbulent structures do not exist independent of the flow itself, so it is with the brain. Mental things, symbols and the like, do not sit outside the brain as programmable entities, but are created by the never ceasing dynamical activity of the brain. The mistake made by many cognitive scientists is to view symbolic contents as static, timeless entities that are independent of their origins. Symbols, like the vorti- ces of the river, may be stable structures or patterns that persist for a long time, but they are not timeless and unchanging. One of the goals of this chapter is to show how patterns in general emerge in a self-organized fashion, without any agent-like entity ordering the ele- ments, telling them when and where to go. I intend to show that principles of self-organization lie behind all structure or pattern formation, and, later, that the brain itself is an active, dynamic, self-organizing system. This paradigm of understanding how cooperation among the parts of a system generates pat- terns opens up an entirely new (or at least different) research program for the behavioral and brain sciences. What do I mean by understanding? I obviously don't mean some privileged level of analysis where the fundamental units of brain function reside. Or that some molecule constitutes an elementary unit of cognition. Or even, as some would have it, that behavior itself is composed of some fundamental unit, like a reflex or a program, that must be studied and further decomposed, perhaps, into some even more elementary constituents. My point is that we will not be bound to the properties of matter itself, or draw our laws strictly from them. In the theory that I will propose no single level of analysis has priority over any other. The psychologist studying overt behavior doesn't have to look over her shoulder at the neuroscientist studying the insides of the nervous system, or the neuroscientist at the chemist, or the chemist at the physicist, and so on. Understanding will be sought in terms of essential variables that character- ize patterns of behavior regardless of what elements are involved in pro- ducing the patterns or at what level these patterns are studied or observed. To quote Napoleon Bonaparte, \"They may say what they like, everything is organized matter.\" I will try to avoid dualities such as top-down versus bottom-up and macro versus micro because I think they can be misleading. What is macro at one level, after all, can be micro for another. Molecules, for example, are too macroscopic for a particle physicist to study, and too micro- scopic for the typical physiologist. Understanding will come by deploying a particular strategy to investigate complex systems such as human beings, and the reductionism will be to principles (or what I call generic mechanisms), that apply across different levels of investigation. This emphasis is on self-organized pattern formation precisely because we will see that the same principles are at work even though the stuff that is producing the patterns may be very different indeed. Emergent properties are a significant feature of all complex systems in nature, and our goal will be to identify some of the key processes involved in emergence. Details will be shown to be important for understanding how cooperation among the com- ponents of a system creates new patterns in a self-organized fashion. Once we accept this more abstract, pattern level of analysis, we start to see common underlying processes and principles of self-organization that transcend ani- mate and inanimate nature.3 And we start to see how enormously complex behavior can arise from a few simple (but nonlinear) rules. At first blush, all this must appear rather strange. You mean, the reader asks, that some deep relationship might exist between, say, the changing weather pattern and me changing my mind? Sounds totally crazy! But I would say the real question is not whether it's crazy at all, but whether it's crazy (or creative) enough. Chapter 1 WHAT IS A PATTERN? Pattern (pat' em), n. 1. A natural or chance marking, configuration or design; patterns of frost on the window. 2. A combination of qualities, acts, tendencies etc. forming a consistent or characteristic arrangement: the behavior patterns of teenagers.4 Everybody knows the world is made up of processes from which patterns emerge, but we seldom give pause to what this means. Maybe it's enough to know a pattern when we see it. Some patterns appeal to us more than others: the beautiful snow crystal, a butterfly's wings, the hive of a honeybee. Pattern is at the heart of great science and art: praise be the one who discovers or creates some underlying unity or truth in the world that surrounds us. Human beings are exceptional at detecting patterns even when the patterns are em- bedded in a field of randomness and disorder, as we will see later (chapter 7). I often tell my students that the genius of Galileo was that he could abstract the relation (form a pattern in his mind) between a ball rolling down an inclined plane and the motions of the planets. Even the greatest intellectual achievements of human beings have to do with patterns. When we talk about patterns, we step back from things themselves and concentrate on the relations among things.5 My main concern will be with the behavioral patterns or modes of organized behavior produced by living things on different levels of description. Although I won't try to explain the behavior patterns of teenagers (at least just yet), I will extricate elementary concepts and principles that apply to all of pattern formation, relatively independent of who or what the component elements are. And since patterns continually form and change, I will introduce some of the main concepts and tools that scientists use to describe their evolution. KINDS OF PATTERNS Most of an organism most of the time is developing from one pattern to another not from homogeneity into a pattern. —A. M. Turing The brilliant Englishman Alan Turing, whose name is often associated with the development of the digital computer (and breaking the secret code used by the Nazis in WWII) had a lesser-known but profound interest in how patterns form in nature.6 I put his words up front because they capture the essence of the kinds of patterns on which I wish to concentrate. First, Turing's reference to organisms places an emphasis on the patterns produced in ani- mate nature (see box). It will turn out, however, that the basic pattern-forming principles apply to both animate and inanimate systems. The caveat, of course, is that an inanimate system, say, a fluid or a chemical reaction, must be far from thermal equilibrium. Enormously interesting and How Nature Handles Complexity THE TWO SIDES OF TURING I am reminded of a famous scientist who was always arguing that the brain is not a Turing machine. When I noted during one of his lectures that there was another Turing, he was quite adamant: \"No, No, there's only one Turing. You know, the Turing of the Turing machine!\" After writing some equations on the blackboard describing chemical patterns, he paused and stared at me. \"Ah, 1 see what you mean,\" he said. The equations that he had written on the board were the very ones Turing used to describe \"the chemical basis of morphogenesis\" in a remote paper published in 1952. My \"two Turings\" refer to the genius who, on the one hand, made significant contributions to programmable computers, and on the other, showed how patterns in nature can emerge without any programmer at all. Only quite recently have the patterns predicted by Turing been observed experimentally, and Turing's theory still figures quite prominently in developmental biology.7 important structures studied by physicists, such as ferromagnetism, or super- conductivity in which matter changes its microscopic structure as the tempera- ture is lowered, are not our primary interest. And even though we might find ice crystals beautiful to look at, they are too orderly and rigid states of matter to be of relevance here. Systems in thermodynamic equilibrium are as dead as anything can be. Only systems that are pumped or energized from the outside (or, like living systems who happen to possess metabolic machinery, from the inside and the outside) are capable of producing the kinds of patterns and structures that interest us. These are called open, nonequilibrium systems: open in the sense that they can interact with their environment, exchanging energy, matter or information with their surrounds; and nonequilibrium, in the sense that with- out such sources they cannot maintain their structure or function. In the last twenty years or so, tremendous progress has been made in understanding how patterns form in open, nonequilibrium systems, especially by my friend and colleague Hermann Haken.8 Thanks to him and others,9 ordinary matter, under certain conditions, has been shown to exhibit lifelike properties. I will draw especially on Haken's work because it provides the theoretical foundation for some of the later developments in neuroscience and psychology that are the primary focus of this book. My aim is to show how principles of pattern formation may be adapted for and tailored to special features of living things, how they perceive and act, leam and remember. Another reason why Turing's quotation captures what we are after is that he emphasizes that even primitive organisms are not structureless things com- posed of homogeneously distributed elements. They always have some kind of intrinsic organization. Although this seems rather obvious, it will turn out that profound consequences result from recognizing that organisms are not tabulae rasae. Many scientists who study learning, even at the cellular level, fail to appreciate this point, which I will develop in chapter 6. Parenthetically, Chapter 1 the important role of intrinsic organizational processes resonates strongly with early Gestalt theory in psychology, which sought natural principles of autonomous order formation in perception and brain function (see chapter 7). As we will see, entirely new concepts of self-organizing dynamical systems are necessary to replace the older physical ideas available to the Gestaltists. Relatedly, becoming is a process of change, and this change often takes the form of an order-order transition from one pattern to another. The famous physicist Erwin Schrodinger, who earned the Nobel Prize for his contributions to quantum mechanics (the Schrodinger wave equation), also stressed the principle of order-order transitions for understanding life.10 He considered the physicists' emphasis on disorder-order transitions as completely irrelevant to the emergence of life processes. In physics, different aggregate states of matter—solid, liquid, gaseous—are called phases, and the transitions between them are called phase transitions. When vapor changes to liquid and eventually to ice, this is an example of progressive change from disorder to order. We see immediately that life processes have nothing to do with this kind of phase transition, and that entirely different principles having to do with nonequilib- rium phase transitions are required. Finally, Turing's reference to developing and evolving patterns stresses the dynamic aspect of pattern formation and even the continuously changing nature of the patterns themselves. For this reason, the principles we seek are for dynamic patterns, not static ones. All structures in animate nature are actually dynamic. We tend to think of some of them as static, but this is not really the case. Here I will adopt the view that structures and behaviors are both dynamic patterns separated only by the time scales on which they live. PRINCIPLES OF DYNAMIC PATTERN FORMATION Any principle of pattern formation has to handle two problems. The first is how a given pattern is constructed from a very large number of material components. We might call this the problem of complexity of substance. The brain is an example par excellence of a compositionally complex system. It has approximately 1010 neurons, each of which can have up to 104 connections with other neurons and 50 plus neurotransmitters (chemicals that are neces- sary for the neurons to work). Second, any principle of pattern formation must address not just how one pattern but many patterns are produced to accom- modate different circumstances. Biological structures like ourselves, for example, are multifunctional: we can use the same set of anatomical components for different behavioral functions as in eating and speaking, or different components to perform the same func- tion (try writing your name with a pencil attached to your big toe). We might call this second problem the problem of pattern complexity. Moreover, how a given pattern persists under various environmental conditions (its stability) and how it adjusts to changing internal or external conditions (its adaptability) have to be accounted for. The processes that govern how a pattern is selected How Nature Handles Complexity from myriad possibilities must be incorporated in any set of organizational principles for living things. These processes often involve cooperation and competition, and a subtle interplay between the two. Dynamic Instabilities To explain the mechanisms underlying pattern formation, let's use the familiar example of a fluid heated from below and cooled from above. First, a word of caution. No one is saying that the brain (or living things in general) is simply a fluid composed of homogeneous elements. Far from it. Rather, the fluid as used here illustrates some of the ways nature handles complex nonequilibrium systems containing many degrees of freedom. In particular, it allows us to illustrate the key concepts of pattern formation and change that will provide a foundation for understanding the emergence of biological order and change. Like all great physical experiments, the beauty of the fluid example—called the Rayleigh-Benard instability—is that even though it is performed in the laboratory, it opens the view to the bigger picture, such as weather patterns, cloud formation, and turbulence in fluids. This idea of choosing (some might say inventing) an experimental model system that adequately captures some of the essential features of the bigger (real world) problem will be a crucial theme throughout this book. I often do a version of the Rayleigh-Benard experiment with my daughter when 1 fry an egg for her on a Saturday morning. She gets a charge out of the patterns that form in the oil as it's heated. Here's how it goes (figure 1.1). Take a little cooking oil, put it in a pan, and heat it from below. If the temperature Figure 1.1 (Left). A layer of liquid heated weakly from below displays no macromotion. The liquid is in a rest state, as indicated by the ball resting in the minimum of the potential well. (Right). At a critical value of the temperature gradient the liquid displays macrosopic rolling motions. The ball can assume one of two possibilities, rolls rotating in one direction or the other. Chapter 1 difference between the top and bottom of the oil layer is small, there will be no large-scale motion of the liquid. Notice the liquid contains very many molecules, and the heat is dissipated among them as a random micromotion that we cannot see. We call this heat conduction. Now already we see this is an open system, activated by the application of a temperature gradient that drives the motion. As this driving influence in- creases, an amazing event called an instability occurs. The liquid begins to move as a coordinated whole, no longer randomly but in an orderly, rolling motion. The reason for the onset of this motion is that the cooler liquid at the top of the oil layer is more dense and tends to fall, whereas the warmer and less dense oil at the bottom tends to rise. The resulting convection rolls are what physicists call a collective or cooperative effect, which arises without any external instructions. The temperature gradient is called a control parameter in the language of dynamical systems. Note that the control parameter does not prescribe or contain the code for the emerging pattern. It simply leads the system through the variety of possible patterns or states. Rolling motions are not the only possibilities. In an open container, surface tension can also affect the flow. The net effect of this force is to minimize the surface area of the fluid, causing tesselation of the surface and the formation of hexagon cells (figure 1.2 and plate 1). In the center of each hexagon, liquid rises, spreads out over the surface, and sinks at the perimeter where the Figure 1.2 (Top) Convection rolls in the fluid as viewed from above. (Bottom) Tesselation of the liquid surface with hexagonal cells. Where the tension is greatest the surface becomes puckered, reducing surface area (Reprinted with permission from reference 13. Copyright © (1980) by Scientific American, Inc. All rights reserved. How Nature Handles Complexity hexagons join. An important point is that two quite distinct mechanisms— one to do with buoyancy and the other surface tension—can give rise to the same dynamic pattern. Thus, the mechanism-pattern relation is not necessarily one to one. Similarly, the same mechanism can give rise to different patterns. This will turn out to be a dominant characteristic of biological systems as well, which we will have to explain. Self-Organization Such spontaneous pattern formation is exactly what we mean by self-organiza- tion: the system organizes itself, but there is no \"self,\" no agent inside the system doing the organizing. A single Benard preparation might contain something on the order of 1020 molecules, each of which is subject to random disordered motion. But once the rolling motion starts, even in parts of the fluid, all these molecules begin to behave in a coherent fashion. The system is no longer merely a haphazard collection of randomly moving molecules: billions of molecules cooperate to create dynamic patterns synchronized in time, and extending over large distances in space many orders of magnitude larger than the molecular interaction. It's like a wave in Yankee stadium: the individual fans communicate and cluster together in groups to create a nearly synchronized pattern that spreads throughout the stadium. In the Rayleigh-Benard system the amplitude of the convection rolls plays the role of an order parameter or collective variable: all parts of the liquid no longer behave independently but are sucked into an ordered, coordinated pattern that can be described precisely using the order parameter concept. Where does this order parameter concept come from? It really comes out of what mathematicians call linear stability analysis (in our example, analysis of the equation of motion that describes the oil's behavior, which we won't go into here). The basic idea is that the initially random starting pattern can be considered as a superposition of a whole bunch of different vibratory modes described by this equation. For a given temperature gradient some (most) of these modes will be damped out. But others will increase in velocity, and the mode or pattern with the biggest rate of increase will dominate. This principle of the most unstable solution, called the slaving principle of synergetics,11 serves as a selection mechanism: from random initial conditions a specific form of motion is favored. It's this coherent pattern that is described by the order parameter, and it is the order parameter dynamics that characterizes how patterns form and evolve in time. One of our main questions will be, what are the relevant collective variables and collective variable dynamics for complex systems such as the nervous system? / Collective Variables and Circular Causality We should clarify one further important aspect of the collective variable or order parameter notion. In synergetics, the order parameter is created by the Chapter 1 CL Excuse me your Honor, but I believe I was here first. Figure 1.3 The chicken and egg problem according to Farcus. (Reprinted with permission from Universal Press Syndicate) cooperation of the individual parts of the system, here the fluid molecules. Conversely, it governs or constrains the behavior of the individual parts. This is a strange kind of circular causality (which is the chicken and which is the egg?), but we will see that it is typical of all self-organizing systems (figure 1.3). What we have here is one of the main conceptual differences between the circularly causal underpinnings of pattern formation in nonequilibrium sys- tems and the linear causality that underlies most of modern physiology and psychology, with its inputs and outputs, stimuli and responses. Some might argue that the concept of feedback closes the loop, as it were, between input and output. This works fine in simple systems that have only two parts to be joined, each of which affects the other. But add a few more parts interlaced together and very quickly it becomes impossible to treat the system in terms of feedback circuits. In such complex systems, as W. Ross Ashby elegantly pointed out years ago, the concept of feedback is inade- quate.12 What is more important is to realize that richly interconnected sys- tems may exhibit both simple and complex behavioral patterns. Returning to the Benard example, there is no reference state with which feedback can be compared and no place where comparison operations are performed. Indeed, nonequilibrium steady states emerge from the nonlinear interactions among the system's components, but there are no feedback-regulated set points or refer- ence values as in a thermostat. Hence in the present case the questions of who sets the reference value, who programs the computer, who programs the programmer, and so on do not even arise. The child who breaks open a toy to find out how it works would be very disappointed if that toy was self- organized. Self-organizing systems have no deus ex machina, no ghost in the machine ordering the parts. How Nature Handles Complexity \\Jq Figure 1.4 The corresponding bifurcation diagram and potential landscape V for the fluid behavior shown in figure 1.1. R is the control parameter and q represents the state of the fluid. Solid (open) balls represent stable (unstable) states of the potential. Similarly, thick lines are stable, dashed line is unstable. Symmetry Breaking Fluctuations A few more surprises are in store for us with this simple physical example. If we look at the arrangement of the convection rolls we see that their motion can be either in one direction or the other (see figure I.I). Once this direction of motion begins in a particular cell, it will not change. But how does the fluid decide which way to go? The answer is Lady Luck herself. The symmetry of left- and right-handed motion is broken by an accidental fluctuation or perturbation. Of course, no agent-like entity inside the system decides which direction the fluid must go. Certainly, a decision appears to be made, but no decision maker tells the fluid what to do. Bifurcations Naturally, if one had a perfect system it would be equally probable that the rolls would go in one direction or the other. A good way to visualize this is the bifurcation diagram (figure 1.4). Below the critical control parameter value, R, for the onset of coherent motion, the only possible macroscopic state is the state of rest. The little ball representing the state of the fluid, q, is in the minimum of the potential, V(q). At the instability point (shown by the arrow), a bifurcation (or branching) from this state of rest occurs: two rolling motions whose rotation speed is equal but opposite emerge spontaneously. Only one, of course, is realized in an experiment. Graphically, the little ball ends up in one well or the other. Notice the previously stable state (rest) is now unstable, shown by the dashed line in the bifurcation diagram and the open ball at the maximum of the potential. 10 Chapter 1 This is a classic example of a pitchfork bifurcation (looks exactly as it sounds) between the state of rest and the state of macroscopic motion in one direction or the other. A stable solution of the dynamics becomes unstable, and a transition to bistability occurs. Bifurcations will be a persistent theme running throughout this book for a number of reasons. Here I'll just mention two. First, bifurcations constitute a mechanism for change and flexibility. Needless to say this isn't the smooth, inexorable gradual change advocated, for example, by Charles Darwin for the process of evolution. In self-organizing systems, a small change, say, in the temperature gradient applied to a fluid can produce a huge collective effect. Second, the bifurcation pictured in figure 1.4 nicely shows how open systems often have several options (here just two) for the same environmental conditions. Chance decides which solution nature adopts. Fluctuations are thus crucial to understanding how patterns are formed. They are always probing the stability of the system, allowing it to discover new and different ways to solve problems. Of course, fluctuations are intrinsic to all natural systems, not just a source of noise to be damped out. In certain cases that I'll describe later, they may actually help amplify weak background sig- nals, a phenomenon that physicists and engineers refer to as stochastic reso- nance (see chapter 7). Although our bifurcation picture only shows the first convection instability, more and more complex patterns—a whole hierarchy of instabilities—may arise if the temperature gradient is further increased. New patterns are created again and again in ever increasing complexity, until eventually the behavior becomes irregular and even turbulent. The components of the system (the fluid molecules) have almost too many options to adopt, and behavior never settles down. The analogies to society, the economy, and our mental health, although potentially misleading, are almost too powerful to overlook. Origins of Instabilities: Competition versus Cooperation The story is not quite over. A little more has to be said about the origins of instability. These are, I think, quite universal and will be important when we come to matters of the nervous system and behavior. As I said before, convec- tive motion in the Benard experiment is an example of a collective effect, which means cooperation among the many parts of the system. Lurking un- derneath this cooperativity, however, is competition. The competition, in this case, is between how forcefully we drive the system (buoyancy forces in the experiment are directly related to the temperature difference) and how well the system holds itself together (governed by two dissipative forces, viscosity and thermal conduction). The ratio of driving forces to dissipative forces is called the Rayleigh number (R in figure 1.4). It is dimensionless, since force quantities occupy the numerator and the denominator of the ratio, and these cancel, leaving just a number. Subsequent instabilities depend on a second dimensionless number called the Prandtl number, which is the ratio of viscosity (the stickiness of the fluid n How Nature Handles Complexity or the strength of intermolecular attraction) to thermal conductivity. But the message in each case is the same: once one force overcomes the other, instabil- ities arise, leading to rich and eventually irregular dynamic behaviors. Later on we will see in other kinds of systems, including the brain, that self-organiza- tion may arise due to competition not among conventional forces but among different sources of information. For now, the word \"information\" substitutes for the kinds of influences (external and internal) that affect the behavior of living things. An important point that will emerge is that information is meaningful and specific to the dynamic patterns that biological systems produce. A further, somewhat related point has to be made before leaving our example and considering what this all means. Rayleigh and Prandtl numbers are dimensionless variables that deal with force fields. They tell us about how instabilities develop, and lead to pattern formation in physical and chemical systems. But it appears that we're left out something quite important. What role, if any, does the environment play? Now this has nothing to do with force in any conventional physical sense, but it does have to do with geometry. In the Benard example, the geometry takes the form of a third relevant dimensionless quantity called the aspect ratio, which relates a typical lateral (horizontal) dimension to the depth of the fluid. But unlike the temperature gradient that expresses the balance of forces and flows in an irreversible process, the aspect ratio is an environmental manipulation that measures the specific influence of lateral boundaries on convective patterns.13 Oil in a circular dish, for example, may give rise to the beautiful hexagonal honey- comb that is observed when the cell structure of the Benard instability is viewed from above (plate 1). It's just this that excites my daughter on Satur- day mornings when we fry an egg. Turing Instabilities Another class of dynamic pattern is analogous in many ways to the Benard system, but based instead on reaction-diffusion processes. Reaction and diffu- sion turn out to be enormously important in chemical pattern formation, but the reason for discussing them here is that they may also play a role in morphogenesis, how biological pattern and form originates. Our friend Turing shows up again, because his pioneering paper \"The chemical basis of morpho- genesis,\" provided major insights into the problem. The story is told that when he was twelve years old, Turing entertained himself one summer by extracting iodine from seaweed. Some years later he won the science prize at his school for a mathematical analysis of an iodine clock reaction. Given this apparent preoccupation with iodine, it's fortuitous that Turing patterns were first unambiguously established in an iodine reaction, first by Patrick de Kepper's group in Bordeaux, France (1990), and shortly afterward by Harry Swinney's group in Austin, Texas.14 12 Chapter 1 13 In his 1952 paper Turing showed that a spatially homogeneous distribution of chemicals (i.e., no pattern) could give rise by a so-called Turing (or diffusion- driven) instability to spatial patterns of different kinds.15 Turing suggested that this reaction-diffusion mechanism might explain such patterns as whorled leaves and the tentacle patterns on Hydra. But by far the most eye-catching application was (and is) the dappling patterns on the coats of animals such as the palomino horse, the giraffe, and the leopard. How does the Turing instability work? Usually, diffusion is considered a stabilizing process rather than a source of destabilization. However, an anal- ogy along the lines suggested by mathematical biologist James Murray, who has analyzed the Turing mechanism extensively, may help visualize the essen- tial aspects of this novel idea.16 Consider a forest fire in which a flame front starts to propagate. The fire itself is a source of activation; the firefighters are pilots in helicopters spraying fire retardant, a source of inhibition. If the fire- fighters can spray the trees in advance of the flame front, the trees will be prevented from burning. If they cannot, then the fire will spread and the entire area will become charred. The intuitive idea is that the diffusion coefficient of the inhibitor must be much faster than the diffusion coefficient of the activator. That is to say, when the helicopter pilots see the flame front coming, they move ahead of it quickly, thus preventing the fire spreading into the area they've just sprayed. The charred area then is confined to a finite domain whose spatial pattern depends largely on the diffusion rates of activation (the fire) and inhibition (the firefighters). This basic description applies even if the fire begins in random places, rather than in a single location. Indeed, we can imagine the kind of dappling (spatial inhomogeneity) that would occur if the same scene were repeated around each locally distributed fire. It turns out that one of the main mechanisms for realizing Turing patterns in the laboratory lies in this difference between the effective diffusion coeffi- cients of the reactants. Istvan Lengyel and Irving Epstein showed that the inhibitor substance in the chemical reaction must move quickly relative to the activator.17 When it does, their model predicts exactly what was observed in experiments: a static pattern of dots containing high concentrations of iodine (plate 2). Almost every animal coat pattern, and probably the spots on tropical fishes, can be generated by this single diffusion-driven process. Instead of chemicals reacting in a gel, biological development is viewed as directed by the concentrations in cells of certain kinds of morphogens (hence morphogen- esis). As in our analogy, the basic mechanism is generic: local activation (the fire) plus long-range inhibition (the firefighters). Even though the mechanisms of reaction-diffusion and convection are dif- ferent, the basic principles underlying pattern formation are the same. As a parameter governing the reaction is changed, one of the collective modes characterizing the pattern becomes unstable. All the others modes are stable. The principle of the least stable solution, Haken's slaving principle, runs the show again, and the process is entirely self-organized.18 13 How Nature Handles Complexity Of course, many other factors are involved in biological development that we have not considered here, such as the geometry and scale of the embryonic cells themselves, and the timing of activation and inhibition. Murray provides an in-depth analysis of many of these factors, especially geometry and scale.19 So how, one might ask, does the gene, the unit of inheritance, fit into this picture? Speaking generally, one idea is that genes don't program biological development as if they contained a set of instructions for building an organ- ism. If we calculated the information necessary to construct an organism, the figure is far larger than could ever be stored in DNA. Rather, it looks more as if the role of genes is to act as specific constraints on laws of self-organization. I realize this point is a bit vague at present, but the notion of information as meaningful and specific to self-organized dynamical processes will become a major part of the story later on (see especially, chapter 5). For now, I leave the reader with an anecdote attributed to Turing himself. When asked if his theory could explain the stripes on a zebra, he allegedly replied that the stripes were easy but the horse part was tricky. Some Other Dynamic Patterns Dynamic patterns, as I've emphasized, are not at all limited to inanimate matter. But for now, only a couple of examples. One that I find a little ironic concerns the molecular biologists' bread and butter, Escherichia coli, the com- mon intestinal bacteria. A big splash was made in the New York Times science section (Sept. 1992) of the need for new principles to understand the fact that even single £. coli cells aggregate into tight balls to protect themselves when they are exposed to antibiotics or noxious stimuli. Lo and behold, they form all kinds of fantastic patterns that can't be predicted from the properties of single cells alone! Dynamically patterned organization of unicellular organisms has actually been observed since the 1950s.20 For example, one of the most extensively used models for cell patterning in development is the cellular slime mold Dictyostelium discoideium. When you remove the food supply of this little beast, the individual cells aggregate into a multicellular slug that can move about quite independently. When the slug stops moving, a fruiting body forms with densely packed spores. This eventually bursts apart, the amoebae are distributed, and the process begins all over again. Just as the molecules in the fluid interact with each other, so the single amoebae communicate by secreting an attractant whose concentration grows as more and more cells come into contact with it. Wave patterns form in a self-organized fashion entirely analogous to the Benard instability. A second example, perhaps closer to home, concerns how the visual cortex forms.21 This depends mostly on the spontaneous activity of the nervous system even without experience of visual stimuli. The big question is how organized regions in cortex, such as ocular dominance columns, can form based only on spontaneous neural activity. It turns out that an instability 14 Chapter 1 15 mechanism, in the generic sense, also causes formation of ocular dominance patterns. From an initially random state in which all neurons in visual cortex receive roughly equal signals from the left and right eyes, symmetry is broken. Randomness is disrupted because neighboring cells are more likely to fire together. Like amoebae coupled by an attracting medium, when cells fire together, their connectivity is enhanced. Although initially each individual cortical neuron has an equal chance of connecting to the left or right eye, this balanced state is unstable. But all it takes is for one eye to be slightly more successful than the other in activating a single cortical neuron, and before you know it a preference for that eye is set up. Once again, the final dominance pattern is the one that dominates all the others that are mixed together to form the initially random state. The way you predict which ocular dominance column is going to form is to perturb the system a little bit, and observe at the moment of instability which pattern grows the fastest. This is the one that wins the \"battle\" between the two eyes. Note again that the cortices of animals and people are not solely static structures, but are sculpted by dynamical processes. Dynamics gives meaning to geometrical forms while also being constrained by them. In short, the creation of structured forms such as ocular dominance columns in the cortex is activity dependent. As I said at the beginning of this chapter, the classic dichotomy between structure and function fades, and we begin to sense the intimate relation between them. Ultimately, all we are left with is dynamics, self-sustaining and persisting on several space-time scales, at all levels from the single cell up. THE MESSAGES OF SELF-ORGANIZED PATTERNS Nature is not economical of structures—only of principles. —Abdus Salam People and brains are not fluids or soap bubbles, as one well-known psycholo- gist insisted after one of my lectures a few years ago. Brains obviously are highly interconnected entities, not continuous media. Life is not a bowl of cherries .. . or lime jello, for that matter. So what can we learn about people and brains from the classic example of the Benard instability? Obviously, the point here is that it's the organizational concepts that matter, because they pertain to how complex structures or patterns can emerge and sustain them- selves without any detailed instructions whatever. Such behavior is essential to the nature of things, and is not imposed from the outside. The Benard example nicely illustrates the interplay between chance (fluctuations) and necessity (order) in effecting selection in a self-organized fashion. We will have other more pertinent examples later. Indeed, synergetic concepts shed an entirely new light on neo-Darwinism, which tends to ignore principles of self-organization in nonlinear dynamical systems. 15 How Nature Handles Complexity We have seen how it is possible for structure and pattern to come \"for free\": under certain conditions the organization of matter undergoes abrupt change, almost without warning. Later on we will see that identifiable signa- tures or fingerprints can be detected in advance of upcoming change. For now, let's try to extract some of the main conceptual themes of pattern formation thus far, with the aim of using them to motivate our studies of brain and behavior. By summarizing the situation, my aim is to consolidate some of the key ideas that will turn up again and again throughout this book. Elementary Concepts of and Conditions for Self-Organization 1. Patterns arise spontaneously as the result of large numbers of interacting components. If there aren't enough components or they are prevented from interacting, you won't see patterns emerge or evolve. The nature of the interactions must be nonlinear. This constitutes a major break with Sir Isaac Newton, who said in Definition II of the Principia-. \"The motion of the whole is the sum of the motion of all the parts.\" For us, the motion of the whole is not only greater than, but different than the sum of the motions of the parts, due to nonlinear interactions among the parts or between the parts and the environment. 2. The system must be dissipative and far from (thermal) equilibrium. Due to nonlinear interactions in the system, heat or energy doesn't diffuse uniformly but is concentrated into structural flows that transport the heat (dissipate it) more efficiently. As a result of dissipation, many of the system's degrees of freedom are suppressed and only a few contribute to the behavior. Intuitively, dissipation is equivalent to a kind of attraction that may take several forms (see 7 below). 3. Relevant degrees of freedom, those characterizing emerging patterns in complex systems, are called collective variables or order parameters in synergetics. An order parameter is created by the coordination between the parts, but in turn influences the behavior of the parts. This is what we mean by circular causality, which, incidentally, is not the same as tautology. 4. Order parameters are found near nonequilibrium phase transitions, where loss of stability gives rise to new or different patterns and/or switching be- tween patterns. Order parameters may exist far from transitions as well, but it is difficult to identify them. 5. Fluctuations are continuously probing the system, allowing it to feel its stability and providing an opportunity to discover new patterns. Fluctuations are positive sources of noise, not just something to be rid of. 6. Parameters that lead the system through different patterns, but that (unlike order parameters) are not typically dependent on the patterns themselves, are called control parameters. Such control parameters may be quite unspecific in nature; that is, in no sense do they act as a code or a prescription for the emerging patterns. On the other hand, we will see that in biological systems 16 Chapter 1 17 The Big Picture ! Experimental- Theoretical Paradigm Control Parameters Material Complexity Dynamic Instabilities Pattern Formation and Change Collective Variable Dynamics Pattern! Behavioral Complexity Figure 1.5 Summary of the big picture, from material complexity to behavioral complexity. boundary conditions may be quite specific in an informational sense, especially when a particular pattern is required (cf. chapters 5 and 6). 7. The order parameter dynamics, the equation describing the coordinated motion of the system, may have simple (fixed point, limit cycle) or compli- cated solutions including deterministic chaos and stochastic (random) aspects thereby giving rise to enormous behavioral complexity. Thus the main picture so far (summarized in figure 1.5) is that the complex- ity of matter or substance with all its microscopic constituents, gives rise through the dynamical mechanism of nonequilibrium phase transitions to simpler (lower-dimensional) order parameter dynamics that in turn are capable of generating enormous behavioral complexity. Nobel laureate Murray Gell- Mann is credited with saying, \"Surface complexity arises out of deep simplic- ity.\" But actually we will see that the opposite is also true, namely, that surface simplicity emerges out of deep complexity.22 That message will ring out loud and clear when we consider in later chapters the experimental evidence in fields dealing, for example, with the coordinated behavior of people and brains. The Tripartite Scheme I want to say a little bit more about the generality (some might say universal- ity) of the theoretical framework summarized here, and about the kinds of 17 How Nature Handles Complexity rules or laws that constitute the order parameter dynamics. The central idea is that understanding at any level of organization starts with the knowledge of basically three things: the parameters acting on the system (which are some- times equated with the term boundary conditions), the interacting elements themselves (a set of primitives), and the emerging patterns or modes (coopera- tivities) to which they give rise. The minimum requirements for characterizing a coherent or cooperative process rest with what I call the tripartite scheme. Harking back to my earlier comments on the relative status of macro and micro, we can appreciate that this is not a rigid picture. Especially in biological systems, constraints and borders are constantly being created and dissolved. Cooperativity at one level of organization may act as a parametric boundary condition on a lower level. Conversely, the former may act as an elementary or component process at higher levels of organization. Mind you, no value is meant to be assigned to the words \"higher\" and \"lower\" as if one level is better or more funda- mental than the other. I simply mean the levels above and below where the cooperativity (pattern, structure) is observed. The present scheme is thus level independent and hierarchical, but not, remembering circular causality, unidirectional. Simple Laws for Behavioral Complexity Now a few words about order parameter dynamics and behavioral complex- ity. And a word of caution as well. In complex systems, as I've emphasized, we have to find the order parameters and control parameters on a chosen level of description. Then we have to identify the order parameter dynamics. There's no free lunch here. It's extremely unlikely that a single master equa- tion set will appear out of the blue. Rather, this book deals with events level by level, looking within and across levels for similarities. The details are always going to differ, but if the conceptual framework sketched here is on the right track, nature will be seen to employ the same strategy at all levels. That is, the creation and stability of new patterns and the annihilation of old ones will be governed by the same basic mechanisms and principles. What will the equations for the order parameter(s) on any given level, look like? For present purposes, it's more important to focus on what they might do. By definition, the order parameter dynamics are of much lower dimension than the system they describe. Just how low depends on the particular system, but theory is well developed for only a small number of relevant degrees of freedom. The approach, as I've said, works best in dissipative systems in which most of the degrees of freedom are heavily damped. For illustration purposes only, let's take the two-dimensional Henon map with two control parameters. Maps are an important class of dynamical sys- tems that describe the evolution of a variable x in discrete time. Given the value of x at time zero, the map gives xt (x at time 1). Given xl the map gives x2 arid so forth. The Henon map was introduced as a simplified model of a set 18 Chapter I 19 0.25 0.50 0.75 1.00 1.25 1.00 1.10 1.20 1.30 0.00 1 -.10 1.2575 1.2600 1.2625 1.2650 1.2675 1.26937 Figure 1.6 Bifurcation diagram of Henon map xn+1 = A — x* + Byn;yn+i — *„• Boxes marked by arrows indicate successive blowups of parameter regions of A, illustrating the self- similar property of the map. of differential equations formulated by Lorenz to describe fluid flow.23 Here, we simply want to use it to illustrate some key points about the kinds of behavior that can emerge from very simple, but nonlinear rules.24 In figure 1.6 we plot the behavior of just one of the variables, x, of this two-dimensional (x, y) system, as a function of one of the control parameters, A. The other control parameter, B, is fixed at a constant value. As in figure 1.4, this is called a bifurcation diagram, but is rather more complicated than the simple pitchfork shown there. Rather, we see that one solution splits into two at a certain parameter value, and splits again and again as the parameter is changed. The trajectory or orbit of the map (the sequence of values x0,xl, x2, etc.) goes through a cascade of bifurcations leading to deterministic chaos. This, so-called universal bifurcation sequence has been analyzed exten- sively (there are actually a number of different routes to chaos), and has been heavily popularized in part because it produces such a compelling and beauti- ful picture. The goal here, however, is to try to get across what such pictures mean and how they affect the way scientists (especially those interested in brain and behavior) approach problems. For now, our reasoning is mostly by analogy. In the next chapter, analogy will be replaced by a tight theory- experiment relation. 19 How Nature Handles Complexity Y 1.0. 0.0. -1.0. Y 1.0. 0.0- -1.0. Y 1.0. 0.0. -1.0. A=0.25 A=1.10 A=0.75 A=1.13 A=1.00 A=1.20 A=1.05 A=1.25 A=1.30 A=1.31 A=1.35 A=1.40 -1.0 0.0 1.0 -1.0 0.0 1.0 X -1.0 0.0 1.0 X -1.0 0.0 1.0 Figure 1.7 Construction of Henon attractor by successive bifurcations as parameter A is changed (8 is fixed at 0.3). See text. One reason for presenting the bifurcation diagram shown in figure 1.6 is that it is representative of a simple deterministic (but nonlinear) equation that displays both simple and complicated behaviors depending on parameter values. \"Simple\" behavior here means a stable fixed point or periodic (limit cycle) orbit that appears for low values of the parameter, A. This means that all initial values of x (initial conditions) converge on an attractor. An example of a fixed point attractor is a damped pendulum: regardless of how far you displace its bob it will wind down and eventually come to a halt. An example of a limit cycle attractor is a grandfather clock that oscillates with a certain frequency and amplitude determined only by its parameters, not the initial conditions. If perturbed, trajectories outside the limit cycle spiral inward, while trajectories inside spiral outward toward the limit cycle. In figure 1.7 one fixed point is stable until, at a certain parameter value (A = 0.75), it flips between two points, bouncing back and forth in a period 2 orbit. This remains stable for a while until it flips to a period 4 orbit at a new parameter value (A = 1.00) and so forth. Things start to get complicated fast, and eventually (at A = 1.31 in figure 1.7) the strange Henon attractor ap- pears. Note that just as this system is sensitive to parameters, a small change producing a qualitatively different behavior, so too it is quite insensitive to parameters in other parameter ranges. There, one can observe the same behav- 20 Chapter I X -.55 -.60 -.65 -.70 1.0550 1.0600 1.0650 1.0700 1.0750 X -.540 -.545 -.550 1.0715 1.0720 1.0725 1.0730 1.0735 X -.55 -.60 -.65 -.70 1.0550 1.0600 1.0650 1.0700 1.0750 1.0715 1.0720 1.0725 1.0730 1.0735 Figure 1.8 Bifurcation diagram of Henon map illustrates several attractors (multistability) and hysteresis. ior for different parameter values: nothing much happens no matter how we change the parameter, what scientists call a null effect. We've already hinted at some of the attributes of \"complicated\" behavior in the Henon map. Scientists are still finding new features in this simple map (I'll mention one important new one below), and the list here is not intended to be inclusive. Examples of behavioral complexity are the cascading bifurca- tions that occur as parameter A is varied; multistability, where several solu- tions coexist for the same parameter value; and bands of chaotic behavior, always interspersed with stable periodic windows. One of the most famous of these windows is the period 3 orbit. Period 3 refers to an area inside the chaotic region where the behavior of the variable, x, bounces among only three values. Boxes in figure 1.8 (top) marked by arrows show the top branch of period 3. Notice that when parameter A is increasing the onset of the period 3 occurs at a larger value than when A is decreasing. Such shifts indicate the presence of numerous attractors and an important phenomenon called hysteresis. Hysteresis means that when a system parameter changes direction, the behavior may stay where it was, delaying its return to some previous state. This is another way of saying that several behavioral states may actually coexist for the same parameter value; which states you see depends on the direction of parameter change. Where you come from affects where you stay or where you go, just as history would have it. 21 How Nature Handles Complexity At certain well known parameter values (A = 1.4, B = 0.3) the dynamics of the Henon map are strange and chaotic, meaning that nearby initial condi- tions become uncorrelated. Moreover, by zooming in on specific parts of the attractor one can observe its self-similar, fractal structure. In figure 1.6, con- secutive pictures are blow-ups of the behavior inside the small highlighted boxes. This self-similarity is a purely geometrical property of the Henon map itself: the structure of the attractor is repeated successively as one changes the scale of observation. As I've emphasized, geometry and dynamics go together like bread and butter. Another feature that we would love to have in any biological system is the ability to create and annihilate patterns simultaneously according to task re- quirements. Many nonlinear dynamical systems embody this kind of property, the Henon map being a prime example. The reasons why creation-annihilation occurs are quite technical, but have been spelled out by Silvina Dawson and colleagues.25 Intuitively, they show that you need at least two independent critical points26 where both contact-making and contact-breaking bifurcations are possible (figure 1.9, top). At the contact-making critical point, creation of a new form occurs. At the contact-breaking critical point, annihilation occurs. A nice way to see this beautiful flexibility property of low-dimensional dy- namic systems is to magnify parameter regions of the map where one sees reversals of period-doubling cascades (figure 1.9, bottom). It turns out that a surprisingly large range of parameter values exists where such creation- annihilation processes are manifest. One merely has to zoom in to see them. What insights, if any, have been gained by this discussion? And what are the methodological implications? Obviously, simple and complicated behav- iors have been shown to emerge from the same dynamical system. Surface simplicity and surface complexity are both possible outcomes. We don't have to posit a different mechanism for each qualitatively different behavior. Main- stream science tends to make this mistake all the time, and it leads to a huge proliferation of models. I think that this is due at least in part to a one-cause- one-effect mentality and consequent failure to explore the full range of param- eter values in a given experimental system. If one only probes a few parameter values and if one sees something different in each case, one is inclined to offer separate explanations. But as we will see again and again in this book, and as illustrated in the example of the Henon map, how you move through parame- ter space determines what you see. And some of what you see, of course, is very fancy indeed. The mechanisms underlying such behavioral complexity are generic, but nontrivial. What one always finds at the heart of the evolution of complex behavior are dynamic instabilities, bifurcations of different kinds that have to be identified. Complex systems, as we will see, seem to live near these instabil- ities where they can express the kind of flexibility and adaptability that are fundamental to living things. In principle, at least, we can understand that simple, nonlinear laws are capable of generating enormous diversity of pat- tern, seemingly for free. The blood, sweat, and tears enter, however (or the 22 Chapter I 23 unstable contact making contact breaking Figure 1.9 (Top) Contact making and contact breaking. Pieces of the stable (s) and unstable (u) manifolds of a saddle point are shown for five values of the control parameter, /i. Contact making occurs at /i = fi2 a' ^ contact breaking occurs at /t = /i4 at B. (Adapted from reference 25.) (Bottom) Reversals of period doubling cascades in the bifurcation diagram of the Henon map for a fixed range of parameter A (B = 0.3). Notice at a gross scale (top left) the y-axis variable x shows no change. However, at finer scales, orbits are created and destroyed, the inevitable consequence of cascade reversals. 23 How Nature Handles Complexity fun starts), when we try to discover what these laws are. Keeping Shakespeare in mind: There are more things in heaven and earth, Horatio, than are dreamt of in your philosophy. Hamlet, I, v NEW LAWS TO BE EXPECTED IN THE ORGANISM When Schrodinger speculated, in his lectures to the Dublin intelligentsia in the early 1940s, that new laws are to be expected in the organism, the world was at war, and concepts of self-organization in nonlinear dynamic systems far from equilibrium were unheard of.27 The very idea that living systems might involve other laws of physics, hitherto unknown, was quite radical. To Schrodinger's credit, he anticipated that these other laws would require an extension of the laws of physics as established to that date. The modern theory of pattern formation and self-organization in nonequilibrium systems, as exemplified in Haken's synergetics, embraces Schrodinger's order based on order proposal for the organization of living matter. In fact, these new con- cepts apply over a wide range of complex, dynamic behaviors from disorder to order all the way through to deterministic chaos. They are, so to speak, the foundation on which to build and generalize our understanding of some of the more exotic phenomena that I treat in this book. Thus, my answer to the question, is life based on the laws of physics? is yes, with the proviso that we accept that the laws of physics are not fixed in stone, but are open to elaboration. It makes no sense to talk about the laws of physics as if the workings of our minds and bodies are controlled by well known fundamental laws. As I stressed earlier, it will be just as fundamental to dis- cover the new laws and principles that govern the complex behavior of living things at the many levels they can be observed. We should not expect to construct complexity from simplicity (e.g., by some extrapolation of the prop- erties of elementary particles). At each level of complexity, entirely new properties appear, the understanding of which will require new concepts and methods.28 Of course, this is not to deny that ordinary matter obeys quantum mechanics, but, again, it is the principles of (selt)-organized matter at the scale of living things that we are after here. If this sounds like beating a dead horse, I apologize. But as we will see, not everyone (including some of the high priests of physics) agrees. MATTERS OF MIND AND MATTER Mind must be a sort of dynamical pattern, not so much founded in a neurological substrate as floating above it, independent of it. —R. P. Feynman What has been suggested thus far is that over and over again nature uses the same principles of self-organization to produce dynamic patterns on all scales. 24 Chapte 2525 The precise patterns that form may differ from one scale of observation to another, but the basic pattern forming principles are the same. What, then, of the physical basis of mind? Might it too be elucidated by these new concepts of pattern formation? Here again, when eminent physicists and biologists come to consider novel (nay, exotic) properties of living things such as con- sciousness and creativity, they completely ignore (or are ignorant of) theories of cooperative phenomena far from equilibrium. In The Emperor's New Mind, for example, Roger Penrose looks to ties be- tween the known laws of quantum mechanics and special relativity for clues to human consciousness.29 According to Penrose, it will be possible to eluci- date consciousness once this linkage has been established and formulated into a new theory called correct quantum gravity (CQG). For Penrose, conscious- ness, together with other attributes such as inspiration, insight, and original- ity, is nonalgorithmic and hence noncomputable. Fair enough. The human brain is thought to exploit quantum parallelism, that simultaneously available different alternatives coexist at a quantum level. When Penrose or any other mathematical physicist experiences an \"aha\" insight, this cannot, he thinks, be due to some complicated computation, but rather to direct contact with Plato's world of mathematical concepts. Underlying the unity of consciousness (and flashes of genius), it seems, is the unity of Platonic and physical worlds. The precision of quantum mechan- ics and relativity (admittedly SUPERB theories in Penrose's capital classifica- tion scheme) provides \"an almost abstract mathematical existence for actual physical reality.\" I resonate to the theme that concrete reality may, on the one hand, be represented in abstract and mathematical ways, and on the other, that mathematical concepts may achieve a kind of concrete reality. This is what I mean when I propose that the linkage across levels of description in complex systems is by virtue of shared dynamical principles. But in his parlance, I would place Penrose's physics of mind in the TENTATIVE or, to be mischievous, MISGUIDED category of theories. In his fourfold classification of physical theories as SUPERB, USEFUL, TEN- TATIVE, and MISGUIDED, Penrose doesn't even mention theoretical devel- opments that have occurred in the field of nonequilibrium phase transitions that are at the core of pattern formation in open, physical, chemical, and biochemical systems. The brain is a complicated object, yet few, he thinks, would claim that the physical principles underlying its behavior are unknown. Penrose begs to differ and opts for quantum gravity. To the contrary, I believe that understanding mental processes requires new concepts, arising at scales far removed from the quantum level. Psychology, I am saying, is not just applied physics, or, for that matter applied biology. The sought-after oneness or globality of thought emerges, in my view, as a collective, self-organized property of the nervous system coupled, as it is, to the environment. Unlike Penrose, I do not think \"where is the seat of con- sciousness?\" to be a particularly useful scientific question. Consciousness, in my opinion, is unlikely to be seated in any single place in the nervous system How Nature Handles Complexity considered by Penrose, such as the upper brain stem or the cerebral cortex. Following concepts of self-organization, global features of brain function are far more likely to be bound up in the coordination or cooperativity between places. In fact, exciting evidence already exists that such coordination occurs in the brain at a variety of different levels (see chapters 7, 8, and 9). Whether or not coordination is related to consciousness, however, is an entirely different matter. The theory of self-organized pattern formation in nonequilibrium systems also puts creativity and \"aha\" experiences in a new light. The breakup of old ideas and the sudden creation of something new is hypothesized to take the form of a phase transition. Like Saul on the road to Damascus, a fluctuation drives the system into a new state that may be so globally stable it can last forever. An exciting possibility that we will consider is that there may be ways to see these transitions in the human brain. What kind of a thing, then, is the brain? And what is the connection between brain and mind? What's the thread holding the fabric together? Let's put our cards on the table. You will not read here that the brain is a computer that manipulates symbols. Neither the brain nor the neurons that compose it compute, although they may combine signals in ways that seem analogous to addition, multiplication, division, and subtraction. The nervous system may act as if it were performing Boolean functions. But computation is just a metaphor for how the brain works. Thus, the question of how neurons com- pute and the principles of neural computation might be important for engi- neers, but they are irrelevant here. People can be calculating, but the brain does not calculate. People can pro- gram computers, but the brain doesn't program anything, not even the move- ment of my little finger. A computer is a complex structure that exhibits complicated behavior. The brain too, is a complex structure that, at least transiently and in particular contexts, lives on a low-dimensional parameter space where enormously complex behavior is possible. The brain of the neural network field, the brain of artificial intelligence research and its cognates, needs no new physics. The brain inside your head does. The thesis here is that the human brain is fundamentally a pattern-forming, self-organized system governed by nonlinear dynamical laws. Rather than compute, our brain \"dwells\" (at least for short times) in metastable states: it is poised on the brink of instability where it can switch flexibly and quickly. By living near criticality, the brain is able to anticipate the future, not simply react to the present. All this involves the new physics of self-organization in which, incidentally, no single level is any more or less fundamental than any other. THE MIND REVEALED? OR, WHAT THIS BOOK'S ABOUT A short time ago the headline \"The mind revealed?\" appeared in Science, the principal publication of the American Association for the Advancement of Science.30 The main facts behind the hype were remarkably simple (in a sense, 26 Chapter 1 27 probably far too simple). When you move a bar across the eye of a cat, neurons in primary visual cortex, often located quite far apart, display fre- quency locking and phase locking, just as if the neurons were soldiers marching perfectly in step to a pipe band. Neuroscientist Charles Gray and colleagues also found that the correlation between neuronal activities was much greater to a single moving bar than it was if the same two neurons were stimulated by two shorter, separate moving bars.31 The interpretation of these facts is what produced the headline. Sir Francis Crick, the Nobel laureate, and others32 interpreted these phase-locked oscillations as the way the brain links features of an object into a single coherent percept. Since an object seen is often heard, touched, and smelled, such a binding mechanism seems necessary to provide perceptual unity. At any time, the relevant neurons for coding features such as color, motion, and orientation must cooperate to form some sort of global activity. It is this global activity that, in Crick's opinion, is the neural correlate of consciousness. The notion is intuitively appealing in light of our physical examples of self-organization, in which global ordering can emerge from local interactions. \"Local\" in the nervous system, however, refers to connectivity among cells that may themselves be widely separated in space. Nothwithstanding that Gray et al.'s initial observations were on anesthe- tized cats (they have since been reproduced in awake animals), at present there seems to be no special or compelling reason why consciousness (as opposed to some other poorly defined property of living things) should require phase and frequency synchronization. Rather, what I find fascinating about these results is that they might reflect a ubiquitous tendency of nature to coordinate things. A central idea that we will explore is that nature doesn't care what these things are. What matters is the self-organization, the way things cooperate to form coherent patterns. Self-organization provides a paradigm for behavior and cognition, as well as the structure and function of the nervous system. In contrast to a computer, which requires particular programs to produce particu- lar results, the tendency for self-organization is intrinsic to natural systems under certain conditions. Of course, defining the necessary and sufficient con- ditions is one of the most important challenges we face. Many of the ideas and results discussed in this chapter have not for the most part made contact with mainstream cognitive science, neuroscience, and its progeny, cognitive neuroscience (and vice versa, one might add). Science is certainly a highly fractionated enterprise these days, so perhaps it's not so realistic to expect connections to be made among quite specialized fields. But there's more to it than that, I think, and it's exemplified in the following story in which a well-known science writer, Roger Lewin, confronted well-known philosopher of mind-cum-neurobiologist Patricia Churchland: \"Is it reasonable to think of the human brain as a complex dynamical system?\" I asked. \"It's obviously true,\" she replied quickly. \"But so what? Then what is your research program? ... What research do you do?\"33 27 How Nature Handles Complexity The very idea that the brain follows principles of self-organization in which global states might be characterized in terms of collective variables that follow a dynamic capable of generating enormous human behavioral complexity seems anathema to the materialistic reductionist. In this book I will report some results of a research program that I and others have conducted over the last twenty years that seeks to elucidate principles of self-organization for biological systems. Behavior will be the starting point of our analysis. Is behavior itself self-organized? What are the collective variables or order parameters, control parameters, bifurcations, and so on? How do we understand the influence of the environment, intentions, and learning in terms of self-organized dynamical systems? How can informa- tion be conceived as meaningful and specific to dynamical processes? How can dynamics be formulated so that it is commensurate with information? Behavior, in particular, the coordinated actions of animals and people, might seem a strange place to begin our understanding of the brain or mind. But in actual fact, behavior supplies the main route (more a guiding light) into our analysis of mental and brain events. How can one understand the function of the brain without knowing what it's for? How can one make meaningful correspondences between events in different domains without a sophisticated analysis of each? The technological wizardry and fact finding of modern neuroscience has led to a situation in which behavior is largely ignored.34 On the other hand, the main thrust of many recent treatments of complexity and self-organization is with mathematical and computer models. Little contact with experiment is made, and interplay between theory and experiment, so crucial to the devel- opment of science, is lacking. Behavior as a source of insight into principles of self-organization and, importantly, their necessary extension to accommodate the special properties of living things that I shall describe, is virtually ignored. Yet, to my mind, it is just as important to establish that functional behaviors are self-organized as it is to establish that principles of self-organization also govern the operation of the human brain. In fact, the claim on the floor is that both overt behavior and brain behavior, properly construed, obey the same principles. Chapter I","libVersion":"0.3.2","langs":""}