{"path":"W2023T1/W2023T1 Files/10.Psyc.217.Wk4Wed.topost.pdf","text":"1 Lecture 10: Experimental studies ▪ Wednesday, September 27, 2023 Your Teaching Fellows: 003/004: Zahra Abolghasem Bronwen Grocott Vasileia Karasavva Ni An 010: Thalia Lang Malina Lemmons Ruoning Li Irene Wen Lectures: MWF 12:00 PM – 1:00 PM (003); 1:00 PM – 2:00 PM (004); 2:00 PM – 3:00 PM (010) Office hours: Tuesdays 2:00 PM – 4:00 PM 2 Exam prep ▪ Document posted on Canvas (Misc. course content) – tips, and practice questions ▪ Watch Zoom recording ▪ Talk to your groups to get started! 3 Learning Objectives ▪ By the end of this class, you will be able to: ▫ Understand the advantages and disadvantages associated with within-subjects designs ▫ Manage disadvantages of within-subjects designs ▫ Identify different sources of error in measuring DV ▫ Describe the relationship between strength of IV/sensitivity of DV and different experimental designs 4 Types of Studies Non- Experimental Designs Observation (later) Correlation Experimental Designs Between Subjects Pretest- Posttest Design Posttest-only Design Within Subjects Concurrent- Measures Design Repeated- Measures Design Quasi- Experimental Designs (later) 5 Between-Subjects Design ▪ Recall studies we’ve looked at previously 6 Between-Subjects Design ▪ Posttest-only Design 7 Between-Subjects Design ▪ Pretest-Posttest Design 8 Between-Subjects Design ▪ Framework: ▫ Playing violent video games leads people to become more aggressive ■ Builds on previous research ▪ Hypothesis: ▫ After playing violent games rather than observing someone play violent games, one will be more aggressive 9 Between-Subjects Design 10 Between-Subjects Design ▪ Basic study design ▫ Dependent measure: Aggressive/hostile thoughts and feelings ■ Scores on “Multiple Affective Adjective Check List” (Bushman & Geen, 1990) ▪ Prediction ▫ Those who played the violent game would have higher aggressiveness/hostility scores than those who watched others play the violent game Adapted from Calvert & Tan, 1994 11 Between-Subjects Design 0 1 2 3 4 5 6 Pretest PosttestAggressiveness/Hostility Played game Watched game Adapted from Calvert & Tan, 1994 12 Between-Subjects Design ▪ Pretest-Posttest design allows researchers to see changes in scores due to IV ▪ Showing equivalence of groups in pretesting = more evidence to support claim that IV  DV 13 Within-Subjects Design ▪ Concurrent-Measures Design ▫ Participants exposed to both conditions almost at the same time ▫ Associated with single attitudinal or behavioural preference as DV IV Condition 1 IV Condition 2 DVOne Group 14 Within-Subjects Design ▪ Concurrent-Measures Design ▫ Participants exposed to both conditions almost at the same time ▫ Associated with single attitudinal or behavioural preference as DV One Group Which one was more fun? Which one made you feel more aggressive? Which one would you give to your 5-year-old child? 15 Within-Subjects Design 0 5 10 15 20 25 30 35 More fun More aggro GiftFrequency MK v. DC SW SB 16 Within-Subjects Design ▪ Repeated-Measures Design ▫ Participants are exposed to all experimental conditions ▫ DV measured after each exposure DV IV Condition 2 IV Condition 1 DV 17 Within-Subjects Design ▪ Repeated-Measures Design ▫ Participants are exposed to all experimental conditions ▫ DV measured after each exposure 18 Within-Subjects Design 0 2 4 6 8 10 12 MK v. DC SW SBCortisol Level (nmol/L) 19 Between- vs. Within- Subjects Design ▪ Problems with concurrent-measures designs ▫ Severe restriction of research questions and DVs ▫ Strong demand characteristics ▪ Problems with repeated-measures designs (on top of demand characteristics) Carryover effects Order effects Fatigue effects Contrast effects Practice effects 20 Between- vs. Within- Subjects Design ▪ Order (aka: carryover) effects ▫ Participant’s response in one condition is affected by having been in other conditions ▫ The effects of one condition carry over to others ▪ Types of Order effects ▫ Fatigue ▫ Practice ▫ Contrast 21 Between- vs. Within- Subjects Design ▪ Many ways to get around these issues (e.g. counterbalancing) ▫ Counterbalancing switches up order of conditions 22 Between- vs. Within- Subjects Design ▪ Advantages of concurrent-measures designs ▫ Very simple to administer ▫ Very quick to run ▪ Advantages of repeated-measures designs ▫ Serve as own control ▫ Require fewer participants vs 23 Sources of Variability in DV ▪ The Ratio: ▫ What proportion of variability in DV is attributable to IV vs. “error”? ▫ The more random variability in DV, the harder it is to detect effect of IV 24 True Score Theory ▪ Theory in measurement True ability/score Error Observed score 25 True Score Theory ▪ Theory in measurement True ability/score Error Observed score 26 Sources/Components of Variability in DV Conceptual Independent Variable Error Score on DV “Error” Sources of variability in your measure caused by things other than your conceptual independent variable. aka Random crap that messes with our ability to detect effect of IV 27 Sources/Components of Variability in DV Conceptual Variable (IV) Random Error Systematic Error Score on DV “Error” Can be divided into Random and Systematic sources. We can measure and separate Systematic Error only with Repeated Measures designs. aka REALLY random crap that’s messing with us aka Systematic pattern identified within the random crap 2829 Sources/Components of Variability in DV Conceptual Variable (IV) Random Error Systematic Error Score on DV “Error” Can be divided into Random and Systematic sources. We can measure and separate Systematic Error only with Repeated Measures designs. aka REALLY random crap that’s messing with us aka Systematic pattern identified within the random crap 30 Between- vs. Within- Subjects Design ▪ By identifying some random error as systematic error (and removing it)… vs 31 Enjoy Lab 1, and happy studying!","libVersion":"0.3.2","langs":""}